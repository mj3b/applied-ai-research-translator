                                                                              Measuring Agents in Production


                                        Melissa Z. Pan 1 * Negar Arabzadeh 1 * Riccardo Cogo 2 Yuxuan Zhu 3 Alexander Xiong 1 Lakshya A Agrawal 1
                                              Huanzhi Mao 1 Emma Shen 1 Sid Pallerla 1 Liana Patel 4 Shu Liu 1 Tianneng Shi 1 Xiaoyuan Liu 1
                                         Jared Quincy Davis 4 Emmanuele Lacavalla 2 Alessandro Basile 2 Shuyi Yang 2 Paul Castro 5 Daniel Kang 3
                                              Joseph E. Gonzalez 1 Koushik Sen 1 Dawn Song 1 Ion Stoica 1 Matei Zaharia 1 * Marquita Ellis 5 *
                                                       1
                                                         UC Berkeley 2 Intesa Sanpaolo 3 UIUC 4 Stanford University 5 IBM Research


                                                                 Abstract
arXiv:2512.04123v1 [cs.CY] 2 Dec 2025




                                                                                                                       Increasing Productivity                      72.7% (48)
                                              AI agents are already operating in production
                                                                                                                Reducing Human Task-Hours                        63.6% (42)
                                              across many industries, yet there is limited pub-
                                              lic understanding of the technical strategies that                   Automating Routine Labor                   50.0% (33)
                                              make deployments successful. We present the                       Increasing Client Satisfaction            37.9% (25)
                                              first large-scale systematic study of AI agents in                    Reducing Human Training              34.8% (23)
                                              production, surveying 306 practitioners and con-
                                                                                                                            Novel Technology             33.3% (22)
                                              ducting 20 in-depth case studies via interviews
                                              across 26 domains. We investigate why organiza-              Reducing Interdisciplinary Expertise     18.2% (12)
                                              tions build agents, how they build them, how they                 Faster Failure Response Time        18.2% (12)
                                              evaluate them, and what the top development chal-                                 Risk Mitigation   12.1% (8)
                                              lenges are. We find that production agents are typ-
                                              ically built using simple, controllable approaches:                                             0% 20% 40% 60% 80% 100%
                                              68% execute at most 10 steps before requiring                                                          % of Responses
                                              human intervention, 70% rely on prompting off-
                                              the-shelf models instead of weight tuning, and               Figure 1. Reasons practitioners build and deploy AI agents
                                              74% depend primarily on human evaluation. Re-                (N =66): increasing speed of task completion over the previous
                                                                                                           non-agentic (human or non-LLM automation) system (Increasing
                                              liability remains the top development challenge,
                                                                                                           Productivity) is most often selected (73%), while improving opera-
                                              driven by difficulties in ensuring and evaluating            tional stability (mitigating risk and accelerating failure recovery)
                                              agent correctness. Despite these challenges, sim-            is least often selected. Exact question and option descriptions are
                                              ple yet effective methods already enable agents              given in Appendix E.3 (N7). N =66 reflects the filtered subset of
                                              to deliver impact across diverse industries. Our             survey participants working on deployed agents who answered this
                                              study documents the current state of practice and            question. Error bars indicate 95th-percentile intervals estimated
                                              bridges the gap between research and deployment              from 1,000 bootstrap samples with replacements. The question
                                              by providing researchers visibility into production          was multi-select so participants were asked to select all/any bene-
                                              challenges while offering practitioners patterns             fits that applied to them and thus the proportions do not sum to 1.
                                              emerging from successful deployments.
                                                                                                           eral AI scientist [12–14]. This excitement extends beyond
                                                                                                           research prototypes to production systems. Companies re-
                                        1. Introduction
                                                                                                           port agents actively running in diverse domains far beyond
                                        Large language models (LLMs) have enabled a new class              the initial coding focus [15–18], including finance [19–22],
                                        of software systems: AI Agents. We define AI agents                insurance [23–26], and education [27–29].
                                        as systems that combine foundation models with optional
                                                                                                           However, despite widespread excitement about agent po-
                                        tools, memory, and reasoning capabilities to autonomously
                                                                                                           tential [30–33], many question their real value and success
                                        execute multi-step tasks [1–5]. Recent research has demon-
                                                                                                           in production [34–37]: whether agents can deliver on their
                                        strated exciting potential for AI agents across domains from
                                                                                                           promise and where their future lies. For example, a re-
                                        drug discovery [6–8], algorithmic innovation [9–11] to gen-
                                                                                                           cent study reports that 95% of agent deployments fail [37].
                                          *
                                            Project Co-Leads.                                              This stark contrast between the promise of agents and their
                                        Correspondence to: Melissa Z. Pan, Negar Arabzadeh, Marquita       high failure rate raises fundamental questions about what
                                        Ellis <{melissapan,negara,mme}@berkeley.edu>.                      separates successful deployments from failures.

                                                                                                       1
                                                   Measuring Agents in Production

Unfortunately, little information is publicly available on
                                                                                Finance & Banking                                      39.1% (27)
how production agents are built. Why do some agents suc-
ceed while others fail? What requirements must agents meet                            Technology                          24.6% (17)
for production deployment? We lack a systematic under-                         Corporate Services                        23.2% (16)
standing of what methods enable successful agents in the                            Data Analytics              13.0% (9)
real world. Researchers have little visibility into real-world            Research & Development               11.6% (8)
constraints and practices. Are agents failing because models
                                                                            Software Development             10.1% (7)
are not capable enough, or are there other factors at play?
Without understanding how agents actually work in pro-                        Legal & Compliance            8.7% (6)
duction, researchers risk addressing the wrong problems.                        Customer Support            8.7% (6)
Meanwhile, practitioners lack consensus on how to build                       Healthcare Services           8.7% (6)
reliable agents and would benefit from understanding how                                    Retail      4.3% (3)
the industry approaches these fast-evolving systems.
                                                                                            Other                 15.9% (11)
To address this knowledge gap, we present Measuring
                                                                                                 0%    10% 20% 30% 40% 50% 60%
Agents in Production (MAP), the first large-scale systematic                                                     % of responses
study of AI agents in production. We study the practices of
developers and teams behind successful real-world systems                 Figure 2. Application domains where practitioners build and de-
via four research questions (RQs):                                        ploy Agentic AI systems (N = 69). Deployments span a broad
                                                                          range of industries, with the highest concentrations in finance, tech-
RQ1. What are the applications, users, and requirements                   nology (including but not limited to software development), and
        of agents?                                                        corporate services. Additional lower-frequency domains (“other”)
                                                                          are listed in Table 2, totaling roughly 26 distinct domains. Note
RQ2. What models, architectures, and techniques are used                  that this is a multi-class classification question where each system
        to build deployed agents?                                         may be assigned to multiple domain categories.
RQ3. How are agents evaluated for deployment?
RQ4. What are the top challenges in building deployed
        agents?                                                           building agents already deployed in production that serve
                                                                          users and deliver measurable value (Figure 1). This natu-
We answer these questions through an online survey with                   rally biases toward successful deployments and experienced
306 responses and 20 in-depth interviews with agent de-                   practitioners. Our data capture what works today, providing
velopment teams, capturing technical details of production                insight into how the field is developing.
agent development. Our survey respondents are practition-
                                                                          Our study reveals key findings for each research question:
ers actively building AI agents (Figure 4a) across 26 do-
mains, from finance and healthcare to legal (Figure 2). We                RQ1: Productivity gains drive agent adoption. We find
filter the survey data to 86 responses that explicitly reported           that 73% of practitioners deploy agents primarily to increase
systems in production or pilot phases,* which we denote as                efficiency and decrease time spent on manual tasks (Fig-
deployed agents, for the results in the main paper. The full              ure 1). Most systems (93%) serve human users rather than
dataset with all 306 responses appears in Appendix A. For                 other agents or systems (Figure 5a). Regarding require-
in-depth interviews, we study 20 cases from teams build-                  ments, teams prioritize output quality over real-time respon-
ing deployed agents with real users, spanning organizations               siveness: 66% allow response times of minutes or longer,
from global enterprises to startups (Figure 3). Our case stud-            compared to 34% requiring sub-minute latency (Figure 5b).
ies and survey capture deployed agent systems serving user                In-depth interviews reveal that organizations tolerate this
bases ranging from hundreds to millions of daily users (Fig-              latency because agents that take minutes to execute still
ure 4c), providing visibility into high-impact deployments.               outperform human baselines.
This dual approach provides the first empirically grounded
                                                                          RQ2: Simple methods and workflows dominate. 70%
view of the technical methods, architectural patterns, and
                                                                          of interview cases use off-the-shelf models without weight
operational practices behind AI agents in production.
                                                                          tuning (Figure 6), relying instead on prompting. Teams
To provide first-hand data on working practices and real-                 predominantly select the most capable, expensive frontier
world constraints, our study focuses on practitioners actively            models available, as the cost and latency remain favorable
    * Production systems are fully deployed and used by target end
                                                                          compared to human baselines. We find that 79% of surveyed
users in live operational environments. Pilot systems are deployed        deployed agents rely heavily on manual prompt construc-
to controlled user groups for evaluation, phased rollout, or safety       tion (Figure 7), and production prompts can exceed 10,000
testing. Definitions for other stages appear in Appendix E.2 N5.          tokens. Production agents favor well-scoped, static work-

                                                                      2
                                               Measuring Agents in Production

flows: 68% execute at most ten steps before requiring hu-
                                                                     Table 1. Overview of application and their domains from our 20
man intervention, with 47% executing fewer than five steps.
                                                                     case studies. To maintain clarity and confidentiality, similar use
Furthermore, 85% of detailed case studies forgo third-party          cases are aggregated into representative descriptions.
agent frameworks, opting instead to build custom agent ap-
                                                                        Business Operations
plication from scratch. Organizations deliberately constrain
                                                                        Insurance claims workflow automation
agent autonomy to maintain reliability.                                 Customer care internal operations assistance
RQ3: Human verification remains central to evalua-                      Human resources information retrieval and task assistance
                                                                        Communication Tech, Multi-lingual Multi-dialect
tion. The majority of deployed survey agents (74%) rely                 Communication automation services
primarily on human-in-the-loop evaluation, and 52% use                  Automotive communication services
LLM-as-a-judge (Figure 10b). Notably, every interviewed                 Scientific Discovery
team utilizing LLM-as-a-judge also employs human verifica-              Biomedical sciences workflow automation
tion. Because production tasks are highly domain-specific,              Materials safety and regulatory analysis automation
                                                                        Chemical data interactive exploration
public benchmarks are rarely applicable. Consequently,
                                                                        Software & Business Operations
25% of teams construct custom benchmarks from scratch,                  Data analysis and visualization
while the remaining 75% evaluate their agents without for-              Enterprise cloud engineer and business assistance
mal benchmarks, relying instead on online-tests such as                 Site reliability incident diagnoses and resolution
A/B testing or direct expert/user feedback. This pattern                Software products technical question answering
reflects the difficulty of automated evaluation for bespoke             Software DevOps
                                                                        Spark version code and runtime migration
production tasks.
                                                                        Software development life cycle assistance end-to-end
RQ4: Reliability is an unsolved challenge. Practition-                  Software engineer/developer slack support
                                                                        SQL optimization
ers focus most on ensuring agent reliability, spanning cor-
                                                                        Code auto-completion and syntax error correction
rectness, latency, and security. The evaluation challenges
described in RQ3 directly impact the ability to verify cor-
rectness to achieve reliable deployments. Latency impacts            Commercial Agent Surveys. Several prior efforts exam-
only a small subset (15%) of applications as a deployment            ine AI (agent) adoption in production from adjacent per-
blocker, and security represents a manageable concern that           spectives. MIT Media Lab and NANDA Initiative [37]
most deployed agents mitigate through action and environ-            and Challapally et al. [38] study economic viability and
ment constraints.                                                    executive views on return-on-investment from companies
Our findings reveal that reliability concerns drive prac-            attempting to integrate agents. Shome et al. [36] analyze
titioners toward simple yet effective solutions with high            marketing materials for 102 commercial agents and conduct
controllability, including restricted environments, limited          user studies with 31 participants, revealing gaps between
autonomy, and human oversight. For example, develop-                 promised and realized capabilities. Industry reports [33, 39–
ers choose human-in-the-loop evaluation over fully auto-             42] focus on organizational readiness and market trends.
mated techniques and manual prompt engineering over au-              LangChain [43] surveyed over 1,300 professionals on agent
tomated methods because these approaches offer control,              motivations, characteristics, and challenges.
transparency and trustworthiness. Practitioners deliberately         Our work differs in two key ways: (i) Scope: we study
trade-off additional agent capability for production reliabil-       agents actively operating in production; and (ii) Focus: we
ity, and this design pattern already enables a broad spec-           collect engineering-level technical data from practitioners.
trum of applications delivering real-world value (Figure 1).         Our study complements these prior works and offers a new
Production agents represent an emerging engineering dis-             perspective into successful agents, providing insights into
cipline. Our study documents the current state of practice           where the field is heading.
and bridges the gap between research and deployment: we
provide researchers visibility into real-world constraints and       Research Agent Literature Survey. Many prior work
opportunities while offering practitioners proven patterns           examine LLM-powered agents from an academic perspec-
from successful deployments across industries.                       tive [44–49], providing valuable taxonomies of agent de-
                                                                     signs and tracing the evolution of key techniques. Other
                                                                     agent surveys focus on specific aspects: evaluation method-
2. Related Work                                                      ologies [50, 51], security concerns [52], and multi-agent
To our knowledge, we offer the first technical characteriza-         systems [53]. In contrast, our work is an empirical study
tion of how agents running in production are built.                  that collects primary data directly from practitioners build-
                                                                     ing and operating deployed agents. We do not synthesize
                                                                     published research via literature reviews; instead, we con-
                                                                     duct original survey data collection and in-depth case study

                                                                 3
                                               Measuring Agents in Production

interviews to document production practices.
                                                                                                        Mature                          10




                                                                               Company Maturity Level
Single-System Studies. Companies publish papers and
                                                                                                          Late                5
technical blogs on agentic systems [54–62] and open-source
agent implementations [63–67], offering glimpses into                                                   Growth        1
production-related agents. Each paper naturally focuses on                                                Early           3
a single system or domain, creating an information gap: we
lack understanding of common patterns, shared challenges,                                                 Seed        1
and design principles across deployments. We address this
                                                                                                                  0    2 4 6 8 10 12
gap by surveying professionals across diverse industries to                                                           Number of case studies
identify recurring engineering practices, architectural deci-
sions, and challenges.                                               Figure 3. The distribution of source institution maturities across in-
                                                                     depth interview-based case studies. The minority (5/20) are from
3. Methodology                                                       seed-stage startups (validating product-market fit), early-stage star-
                                                                     tups (proving scalable business models), and growth-stage startups
To understand how production AI agents are built and de-             (rapidly expanding market share and operations). The majority
ployed, we conducted two complementary studies: a large-             (15/20) are from late-stage and mature institutions (with estab-
scale public survey and 20 in-depth case study interviews.           lished market positions). The stages are approximated from limited
We detail our survey design and distribution in Section 3.1,         public information e.g. size, sector, and annual recurring revenue.
describe our interview protocol and case study selection
in Section 3.2, and outline our data processing pipeline in
Section 3.3.                                                         tion for this paper ending October 29, 2025.
                                                                     We received 306 valid responses. 294 participants indicated
3.1. Public Online Survey                                            that they have directly contributed to the building and de-
                                                                     signing of at least one agent system. Our survey respondents
We designed and conducted a survey for practitioners build-
                                                                     are predominantly technical professionals such as software
ing AI agents, with a strong focus on the technical details
                                                                     and machine learning engineers (Figure 4a). Among 111
of their systems. The survey covers system architecture,
                                                                     respondents who reported their system’s deployment stage,
evaluation, deployment, and operational challenges through
                                                                     82% indicated their systems are in production or pilot phases
47 questions (listed in full in Appendix E). To capture AI
                                                                     (Figure 4b), demonstrating rapid transition from experimen-
Agents as practitioners understand them, we invited respon-
                                                                     tal prototypes to real-world deployments.
dents to describe systems they refer to as AI Agents or
Agentic AI without imposing a prescriptive definition.               To maintain focus on production systems, we filtered the
                                                                     data to 86 responses that explicitly reported their systems
To ensure relevance, we implemented the survey with dy-
                                                                     as being in production or pilot phases. Production systems
namic branching logic in Qualtrics, where certain questions
                                                                     are fully deployed and used by target end users in live op-
only appear based on previous responses. For example,
                                                                     erational environments, while pilot systems are deployed
the question about the realized benefits of using agents
                                                                     to controlled user groups for evaluation, phased rollout, or
is only shown to respondents who confirmed they chose
                                                                     safety testing. This filtering excludes development proto-
agentic over non-agentic solutions (O3.1.1 and O3.1 in Ap-
                                                                     types, research artifacts, and retired systems, as well as
pendix E.3). This adaptive structure, combined with the op-
                                                                     participants who did not report their deployment stage. The
tional nature of all questions, means each question receives
                                                                     definitions for all deployment stages appear in Appendix E.2
a different number of responses. We report the specific sam-
                                                                     N5. We denote production and pilot systems as deployed
ple size (N) for each result throughout Sections 4–7 in figure
                                                                     agents. All survey statistics presented in this paper refer to
captions. We asked participants to focus their responses on
                                                                     deployed agents unless otherwise stated. Complete data for
a single system if they contributed to more than one agent
                                                                     306 valid responses across all deployment stages appears in
system (Acknowledgment E.1). Full questionnaire details
                                                                     Appendix A.
are available in Appendix E, including the branching logic
in Figures 26 and 27.
                                                                     3.2. In-depth Case Studies
We distributed the survey through multiple channels to reach
practitioners across the AI agent ecosystem: the Berkeley            To add qualitative depth to our survey findings, we con-
RDI Agentic AI Summit [68], the AI Alliance Agents-in-               ducted 20 in-depth case studies through interviews with
Production Meetup [69], the UC Berkeley Sky Retreat [70],            teams building deployed agents across a diverse range of
and professional networks including LinkedIn, Discord, and           organizations.
X. We release the survey on July 28, 2025, with data collec-         We carefully selected our 20 cases to achieve representative

                                                                 4
                                                      Measuring Agents in Production


                                               50.9% (55)                                      45.0% (50)                    25%           8
      Software & ML Engineers                                   In Production                                                                  7
                                                                                                                             20%




                                                                                                            % of Responses
Technical Executive & Managers            31.5% (34)        Pilot Deployment              32.4% (36)                                                   6
                                                                                                                             15%   5
        Academic Researchers      9.3% (10)                         Prototype         19.8% (22)                                                   4
       Infrastructure Engineers 4.6% (5)                            Research 1.8% (2)                                        10%
                                                                                                                                       2                   2
            Technical Writers &                                       Retired 0.9% (1)                                       5%                                1
        Learning Professionals 3.7% (4)
                                                                                                                             0%
                              0% 20% 40% 60% 80%                           0%    20% 40% 60% 80%




                                                                                                                                10 -10
                                                                                                                               10 -100
                                                                                                                              10 -1000
                                                                                                                              10 0-100
                                                                                                                                 k k
                                                                                                                                 0k k
                                                                                                                                    -1m
                                                                                                                                      +
                                    % of Responses




                                                                                                                               10 -100
                                                                                                                              50 0-50




                                                                                                                                   1m
                                                                                   % of Responses




                                                                                                                                   1


                                                                                                                                 0
                                                                                                                                0
                                                                                                                                               Users
                                        (a)                                              (b)                                                    (c)

Figure 4. Overview of survey respondent and system characteristics across all agents the survey data: (a) roles of survey participants by
primary contribution area (N =108), (b) deployment stages of Agentic AI systems (N =111) that survey participants contributed to, and
(c) reported number of end users (N =35) for the Agentic systems survey participants contributed to.


samples across application diversity, organizational matu-               main categories and perform classification. This allowed
rity, and global reach. We only interviewed systems with                 us to normalize phrases from survey responses to represen-
real-world users: 14 cases are in full production and 6                  tative label sets. For instance, we grouped responses like
cases are in final pilot phases. The cases span five key sec-            “healthcare,” “medical,” and “patient monitoring” under a
tors: business operations (3 cases), software development                unified “healthcare” category. Details of this normalization
and operations (7 cases), integrated business and software               process appear in Appendix B.1. All other figures present
operations (5 cases), scientific discovery (3 cases), and com-           results from structured survey questions or interview data
munication services (2 cases). Notably, these deployments                without requiring automated processing.
extend well beyond commonly known coding agents or gen-
                                                                         As described in Section 3.1, our survey data in the main
eral chatbots, demonstrating the breadth of production agent
                                                                         paper are filtered to deployed (production and pilot) agents,
applications. The systems target both internal employees (5
                                                                         and our interviews specifically select teams building de-
cases) and external enterprise consumers (15 cases). Our
                                                                         ployed agents. All results presented in Sections 4–7 refer to
selection includes organizations across maturity levels, from
                                                                         deployed agents from either survey responses or interviews,
seed-stage startups to large enterprises with global footprints
                                                                         which we explicitly denote throughout the paper. Refer to
(Figure 3). For companies with multiple agent deployments,
                                                                         Appendix A for unfiltered full data.
we presented only distinct use cases to maximize application
diversity. The anonymized case studies and their applica-                For all figures that include error bars, we report 95% con-
tion domains appear in Table 1, with additional details in               fidence intervals computed using 1,000 bootstrap samples
Appendix D.                                                              with replacement.
Each interview lasted 30 to 90 minutes and was conducted
by teams of 2 to 5 organizationally neutral interviewers. We             4. RQ1 Results: What Are The Applications,
followed a semi-structured interview protocol covering 11                   Users, and Requirements of Agents?
topic areas (detailed in Appendix D.1), including system ar-
chitecture, evaluation mechanisms, deployment challenges,                We now present findings from our survey and case study
operational requirements, and measurable agent values. We                interviews across four central research questions. We start
anonymized and recorded interviews based on participant                  by examining motivations for agent adoption (Section 4.1),
preferences, with human note-takers capturing insights. To               which agent applications successfully reach deployment
ensure accuracy, we cross-validated final summaries among                (Section 4.2), who uses these systems (Section 4.3), and
all interviewers. Per our confidentiality agreements, we                 what latency requirements shape their design (Section 4.4).
anonymized all data and present findings in aggregate.                   Understanding these patterns reveals where agentic systems
                                                                         deliver practical value and how they transform real-world
                                                                         applications.
3.3. Data Processing
Most survey questions use structured formats (single-                    4.1. Motivations for Choosing Agents
select, multi-select, or numeric), requiring minimal post-
processing. For the free-text domain keyword responses                   Among practitioners with deployed agents who evaluated al-
used in Figure 2, we used LOTUS [71], a state-of-the-art                 ternatives, 82.6% prefer the agentic solution for deployment.
unstructured data processing tool, to identify common do-                We define non-agentic alternatives as existing software sys-


                                                                     5
                                                Measuring Agents in Production

tems, traditional approaches, or human execution. Figure 1            tems serve humans rather than other agents or software
details the specific benefits reported by these practitioners.        systems. As shown in Figure 5a, internal employees are the
The top three drivers all target the reduction of human effort:       primary user base (52.2%), followed by external customers
increasing productivity and efficiency (72.7%), reducing hu-          (40.3%). Only 7.5% of deployed systems serve non-human
man hours (63.6%), and automating routine labor (50.0%).              consumers.
Conversely, qualitative benefits rank lower. Increasing user
                                                                      The focus on internal users is a deliberate deployment
satisfaction ranks in the middle tier (37.9%), followed by
                                                                      choice. Detailed case studies reveal that organizations re-
reducing required human expertise and training (34.8%) and
                                                                      strict deployments to internal environments to mitigate un-
enabling novel technology (33.3%). Accelerating failure re-
                                                                      solved reliability and security concerns. Internal users oper-
sponse times (18.2%), reducing interdisciplinary knowledge
                                                                      ate within organizational boundaries where agent mistakes
requirements (18.2%), and risk mitigation (12.1%) rank last.
                                                                      have lower consequences and human oversight is readily
These priorities reflect pragmatic deployment realities. Or-          available. An example from our case study, internal Pager-
ganizations adopt agents to solve immediate operational               Duty agents respond to employee requests, while human
problems, such as expert-expensive manual work and insuf-             engineers can take over when needed.
ficient staffing capacity. Productivity gains are straightfor-
                                                                      Furthermore, most systems—including external-facing ap-
ward to quantify through human-hour reductions, whereas
                                                                      plications—require domain-specific knowledge to operate.
safety improvements and risk mitigation are harder to verify.
                                                                      For example, insurance authorization agents support nurses,
This focus aligns with our findings on internal deployments
                                                                      and incident response agents support site reliability engi-
(Section 4.3), where organizations tolerate higher error rates
                                                                      neers. This reflects a pattern where agents function as tools
by maintaining human oversight to catch these errors.
                                                                      that augment domain experts rather than replace them. This
The top reported reasons for using agents reveal a trend              paradigm also enables human users to serve as the final
where certain objectives are more verifiable and measurable.          verifiers of agent outputs, which we discuss further in Sec-
For example, time to complete a task (productivity) is con-           tion 6.2.
crete and quantifiable, while risk mitigation benefits takes
                                                                      Beyond user type, we examine the scale of the user base.
longer to verify. We examine this measurement gap and its
                                                                      We find that end-user counts for deployed systems vary
implications for deployed agents in Section 7.1.
                                                                      significantly. As shown in Figure 4c, 42.9% of deployments
 RQ1 Finding #1: Productivity gains through automat-                  serve user bases in the hundreds. However, we also observe
 ing routine human tasks drive agent adoption (73%),                  high-traffic deployments (25.7%) serving tens of thousands
 while harder-to-verify applications like risk mitigation             to over 1 million users daily, representing substantial user
 are less common.                                                     impact or possibly mature systems.

                                                                        RQ1 Finding #3: Deployed agents primarily serve
4.2. Application Domains                                                human end-users (92.5%), which enables close human-
We find that agents operate in diverse industries well beyond           oversight.
software engineering. Figure 2 shows that the three domains
with the highest number of reported deployments in survey             4.4. Latency Requirements
are Finance & Banking (39.1%), Technology (24.6%), and
Corporate Services (23.2%). We also observe a long tail               Relaxed latency requirements are common among deployed
of applications in Data Analytics (13.0%), Research & De-             agents. Figure 5b shows the distribution of maximum allow-
velopment (11.6%), and other specialized domains (15.9%).             able end-to-end latency. Minutes is the most common target,
This distribution demonstrates that agentic systems deliver           followed by seconds. Notably, 17.0% report no defined limit
practical value across fundamentally different industries.            yet, and 1.9% allow hours to days.
                                                                      The latency tolerance reflects the productivity focus from
 RQ1 Finding #2: Deployed agents already operate                      Section 4.1. Agents are often used to automate tasks that
 across 26 diverse domains, well beyond math and coding               typically take humans hours to complete. Consequently, an
 that are popular in research, demonstrating value across             agent taking multiple minutes to respond remains orders
 different industries.                                                of magnitude faster than non-agentic baselines. Interview
                                                                      participants emphasized this advantage: even if an agent
4.3. Users of Agents                                                  takes five minutes, that remains more than 10× faster than
                                                                      assigning the task to a person on the team, especially when
We find that deployed agents primarily serve human users
                                                                      staffing shortages exist and the task is secondary to the user’s
directly. Survey data indicates that 92.5% of deployed sys-
                                                                      core responsibilities. Examples include nurses examining


                                                                  6
                                                   Measuring Agents in Production
                                                                                        60%
       Internal                                                                                              41.5% (22)
    Employees                                         52.2% (35)                        50%




                                                                       Percentage (%)
      External                               40.3% (27)                                 40%          26.4% (14)
    Customers
                                                                                        30%                                                 17.0% (9)
   Non-Agentic       4.5% (3)
     Software                                                                           20% 7.5% (4)
                                                 Human user                                                           5.7% (3)
Other AI Agents    3.0% (2)                                                             10%                                      1.9% (1)
                                                 Non-human user
              0%         20%         40%           60%         80%                      0%




                                                                                                                                 y
                                                                                              nd


                                                                                                       s

                                                                                                             tes

                                                                                                                     urs




                                                                                                                                            et
                                                                                                                             da
                                                                                                     nd




                                                                                                                                       it s
                                                                                              co




                                                                                                           nu

                                                                                                                   Ho
                                % of Responses




                                                                                                     co




                                                                                                                           >1

                                                                                                                                     lim
                                                                                          se




                                                                                                           Mi
                                                                                                   Se
                                                                                        ub




                                                                                                                                  No
                                                                                 <S
                                                                                                             Latency Tolerance
                                      (a)
                                                                                                                     (b)

Figure 5. Overview of Agentic AI deployment characteristics in terms of primary end users and latency requirements: (a) Distribution
of primary end users (N =67), where hatched bars (///) denote human end-users and solid bars denote non-human end-users; and (b)
Reported tolerable end-to-end response latency for deployed systems (N =53). Over 92% of deployed agents primarily serve human
users, and most systems tolerate response times on the order of minutes rather than requiring strict real-time responsiveness.


insurance details and software engineers responding to in-              tuning, reinforcement learning, and automated prompt op-
ternal pager duty. Some deployed agents from case studies               timization—remain uncommon in deployment. Instead,
even batch requests hourly or overnight, further indicating             teams prioritize control, maintainability, and iteration speed.
latency is not a primary constraint.
However, this pattern breaks for real-time interactive appli-           5.1. Model Selection
cations. For example, practitioners building voice-driven               We find that deployed agents rely heavily on proprietary
systems report latency as their top challenge (Section 7.2)             models. Only 3 of 20 detailed case studies use open-source
during detailed case study. These systems compete against               models (LLaMA 3 [72], Qwen [73], and GPT-OSS [74]),
human conversation speeds rather than task completion base-             while the remaining 17 rely on closed-source frontier mod-
lines. Among our 20 detailed case studies, only 5 require               els (Figure 6). Of the teams using closed-source models, 10
real-time responsiveness. The remaining 15 cases tolerate               explicitly confirm using the Anthropic Claude [75] or Ope-
extended processing times: 7 involve human review with                  nAI GPT [76] families. Specific models mentioned during
relaxed timing, 5 operate as asynchronous background pro-               interviews include Anthropic Claude Sonnet 4 and Opus 4.1,
cesses, and 3 have hybrid operation patterns. For these                 and OpenAI o3, each representing the state-of-the-art model
systems, processing times of minutes remain acceptable                  from each provider at the time of the interview. While other
because the alternative is days of human effort.                        participants did not disclose specific models, most inter-
                                                                        viewees followed the pattern of using the largest and most
  RQ1 Finding #4: Development teams prioritize agent                    capable state-of-the-art models as the primary model for
  output quality and capability by concentrating on                     their agents from each model family.
  latency-relaxed applications.
                                                                        We find that open-source adoption is rare and is driven by
                                                                        specific constraints rather than general preference. Among
5. RQ2 Results: What Models, Architectures,                             the three cases using open-source models, motivations in-
   And Techniques Are Used To Build Agents?                             clude high-volume workloads where inference costs at scale
                                                                        are prohibitive, and regulatory requirements preventing data
Having established what problems practitioners target with              sharing with external providers. For example, one team
agentic systems, we now address how these systems are                   from detailed case study serve continuous infrastructure
built. We examine five critical implementation decisions:               maintenance agent leverages the company’s existing inter-
model selection, model weights tuning, prompt construction,             nal compute resources (e.g., GPUs) to serve a fine-tuned
agent architectures, and development frameworks.                        open-source model to meet cost constraints.
Overall, practitioners favor established, straightforward               For the majority of cases, model selection follows a prag-
methods over stochastic or training-intensive techniques.               matic, empirical approach focused on downstream perfor-
We find that methods popular in research—such as fine-                  mance. Interviewees report that they test the top accessible


                                                                   7
                                                                           Measuring Agents in Production

                                 20                                                          reasoning models.
        Number of case studies   15                                                          Operational constraints also drive multi-model adoption.
                                                             14 No(14)                       We find that multi-model architectures can emerge from
                                          17 No(17)
                                 10                                                          lifecycle management needs rather than complex reasoning
                                                                                             requirements for the agent task. Detailed case studies reveal
                                 5
                                                             6    Yes(6)                     that teams maintain multiple models to manage agent’s be-
                                          3    Yes(3)                                        havioral shifts from model migration. Organizations often
                                      Open source       Post training                        run legacy models alongside newer versions because agent
                                                                                             scaffolds and evaluation suites depend on the specific be-
Figure 6. Distribution of model characteristics of case-study sys-                           haviors of the older model, where sudden updates might
tems from our interviews (N =20). The left bar chart shows model                             degrade output quality. Additionally, governance policies
source openness; “Yes” indicates open-source model usage while                               enforce teams to route subtasks to different model endpoints
“No” indicates closed-source or non-disclosed model usage. The                               based on user or developer access levels. Thus, architectural
right bar chart shows whether post-training (e.g. fine-tuning, re-                           complexity often reflects strategic operations rather than
inforcement learning) is utilized (“Yes”); “No” labels non-use or                            task difficulty.
non-disclosure. Overall, most case-study systems rely on off-the-
shelf closed-source models, with comparatively fewer teams using                             Interestingly, we observe a heavier tail towards agents us-
open-source models or performing additional post-training.                                   ing more distinct models when we examine the full survey
                                                                                             data, including prototyping and research agents that have
                                                                                             not yet been deployed (Figure 16a). Deployed agents are
state-of-the-art models for each task and select based on per-                               more likely to converge on fewer number of distinct models
formance. Unlike the high-volume open-source use cases,                                      compared to non-deployed agents, suggesting that teams
these teams note that runtime costs are negligible compared                                  explore richer multi-model combinations during early exper-
to the human experts (e.g., medical professionals, senior                                    imentation but consolidate onto a smaller set of models as
engineers) that the agent augments. Consequently, they de-                                   they move toward deployment. We hypothesize this might
fault to the best-performing closed-source models regardless                                 be also reflecting the additional operational burden of main-
of inference cost.† Additionally, 4 out of 20 detailed case                                  taining many distinct model endpoints.
studies combine LLMs with specialized off-the-shelf mod-
                                                                                              RQ2 Finding #2: The majority of agents coordinate
els (e.g., text-to-speech, chemistry foundation models) to
                                                                                              multiple models, driven not only by functional needs
handle specific modalities.
                                                                                              like modality but also by operational requirements such
  RQ2 Finding #1: Deployed agents predominantly rely                                          as model migration.
  on proprietary frontier models; open-source models are
  used primarily to satisfy cost or regulatory constraints.                                  5.2. Model Weights Tuning
Number of Distinct Models. While a substantial portion                                       We observe a strong preference for prompting over model
rely on a single model, the majority coordinate multiple                                     weight updates in deployed agents. We find that 14 out of
models to meet functional or operational needs. Survey                                       20 (70%) detailed case studies rely solely on off-the-shelf
results show that 40.9% of deployed agents use exactly one                                   models without supervised fine-tuning (SFT) or reinforce-
model, while 27.3% use two, 18.2% use three, and 13.6%                                       ment learning (RL) (Figure 6). Additionally, 2 teams from
use four or more. Among detailed case studies, 10 out of 20                                  detailed case studies explicitly report that foundation model
(50%) combine models to address specific functional needs.                                   capabilities already meet their target use case, making fine-
We identify two drivers: cost optimization and modality.                                     tuning unnecessary.
First, teams combine models of varying sizes to balance                                      Only 5 of 20 detailed case studies actively use SFT. These
latency, cost, and quality. For example, one agent workflow                                  teams target deployment in business-specific corporate con-
from case study routes simple subtasks like pattern recogni-                                 texts where leveraging highly contextual information im-
tion to smaller models while reserving larger models for sub-                                proves downstream performance. For example, customer
tasks requiring higher reasoning capabilities. Second, teams                                 product support agents benefit from fine-tuning on specific
integrate models to handle distinct data modalities. Com-                                    product offerings and policies. However, performance gains
munication agents leverage text-to-speech models alongside                                   do not always justify the development overhead. Among
LLMs, while scientific agents employ domain-specific foun-                                   the 5 detailed case studies actively using fine-tuned models,
dation models (e.g., chemistry) alongside general-purpose                                    3 consider SFT essential, while 2 apply it selectively for
   †
     Rankings based on public model leaderboards at the time of                              enterprise clients where customization requirements justify
development.                                                                                 the additional cost. Three additional teams from interview

                                                                                         8
                                                 Measuring Agents in Production

case studies express strong interest in future adoption for
                                                                                   Manual + AI                           44.6% (25)
similar reasons. Notably, we find that 4 of the 5 detailed
case studies that employ SFT do so in combination with off-                        Fully Manual                     33.9% (19)
the-shelf LLMs, rather than relying on fine-tuned models
exclusively.                                                                  Prompt Optimizer         8.9% (5)
Regarding reinforcement learning (RL), only 1 scientific                   Predefined Template      3.6% (2)
discovery case from our interviews uses an RL post-trained                   Fully Autonomous      3.6% (2)
model. Three other teams express interest in exploring RL
for software testing in future development cycles.                                            0%      20%     40%     60%        80%
                                                                                                         % of Responses
This data, however, does not diminish the value of post-
training models for agent applications. Interviews show                Figure 7. Distribution of prompt construction strategies across de-
that SFT and RL is challenging to implement and brittle                ployed Agentic AI systems (N =53). Overall, the prompting pat-
to model upgrades. Given that off-the-shelf base models                terns indicate that humans remain central to prompt crafting. This
can already do most of what the agent applications need,               was a multi-select question, so respondents could choose all prompt
teams prefer methods with lower integration overhead that              construction strategies that applied.
do not increase already high development and maintenance
burdens.

 RQ2 Finding #3: Practitioners rarely post-train models.               We find that prompt complexity increases with system ma-
 When they do, they selectively apply SFT/RL to specific               turity. Among deployed agents from survey, we observe
 subtasks or clients, typically in combination with general            a wide distribution: while 51.5% of systems use short in-
 LLMs. Teams find prompt engineering with frontier                     structions under 500 tokens, there is a long tail of massive
 models sufficient for many target use-cases already.                  prompts (Figure 8b). Specifically, 24.2% of deployed agents
                                                                       use prompts between 500 and 2,500 tokens, 12.1% use be-
                                                                       tween 2,500 to 10,000. Notably, another 12.1% even exceed
5.3. Prompting Strategies                                              10,000 tokens .
We find that humans dominate system-prompt construction
                                                                         RQ2 Finding #5: Deployment prompt lengths vary
in production systems. Our survey data reveals that 33.9%
                                                                         widely: while half are short (<500 tokens), a significant
of deployed agents use fully manual methods with hard-
                                                                         long tail (12%) exceeds 10,000 tokens to handle complex
coded strings. Another 44.6% use a hybrid approach where
                                                                         contexts.
humans manually draft prompts and then use an LLM to
augment or refine them, and 3.6% rely on utilizing prede-
fined prompt templates. Only 8.9% of respondents use a                 5.4. Agent Architecture
prompt optimizer (e.g., DSPy [77]) to improve their agent              We explore the core architectural patterns that support pro-
systems, and just 3.6% report letting agents autonomously              duction deployment. To ensure clarity, we adopt the ter-
generate their own prompts.                                            minologies visualized in Figure 22: an agent completes a
Our detailed case studies confirm this pattern. Only 1 out             high-level task, which decomposes into logical subtasks,
of 20 (5%) detailed case studies has explored automated                consisting of granular atomic steps (e.g., model calls, tool
prompt optimization. The remaining cases rely on primary               use).
human construction, sometime using LLMs for augmenta-                  Number of Steps. We find that production agents tend
tion. While recent research [77–79] proposes automating                to follow structured workflows with bounded autonomy.
prompts into parametric optimizations, we find these meth-             We ask survey participants how many steps their deployed
ods rare in deployment. We speculate from interview con-               systems execute within a subtask before requiring human
versations with practitioners that they prioritize controllable,       input. Most systems operate within tight bounds: 46.7%
interpretable methods that allow for fast iteration and debug-         of deployed survey agents complete only 1–4 steps, and an
ging over automated or “black-box" methods that requires               additional 21.7% perform 5–10 steps (Figure 8c). A smaller
additional engineering overhead.                                       subset (16.7%) extends to tens of steps, while only 6.7% re-
                                                                       port systems with no explicit step limit. Interestingly when
 RQ2 Finding #4: Human dominates prompt construc-                      we expand the analysis to include all agents including both
 tion as teams prioritize controllability. LLMs are used               deployed and not yet deployed agents in Figure 16c, the
 as secondary tools to augment human-crafted prompts,                  distribution shifts toward substantially higher step counts.
 while automated prompt optimization remains rare.                     This indicates that prototypes and research systems are more
                                                                       likely to run tens of steps or have no explicit limit on au-

                                                                   9
                                                             Measuring Agents in Production

                 50%                                                30%     9                                                 50%   28
                           9                                        25%          8     8
                 40%                                                                                                          40%




                                                                                                             % of Responses
                                                   % of Responses
% of Responses


                                                                    20%
                 30%            6                                                                                             30%
                                                                    15%                        4   4                                     13
                 20%                      4                                                                                   20%             10
                                               3                    10%
                 10%                                                 5%                                                       10%                    3 2 4
                 0%                                                  0%                                                       0%




                                                                                                                                       1-4
                                                                                                                                         0
                                                                                                                                 Hu Tens
                                                                                                                                  ou ds
                                                                                                                                   No nds
                                                                                                                                         it
                                                                     25 50
                                                                     50 00
                                                                     2.5 .5k
                                                                            0k
                                                                            k+




                                                                                                                                     5-1




                                                                                                                                     lim
                       1
                               2
                                    3
                                              4+




                                                                                                                                Th ndre
                                                                        k-1
                                                                         10
                                                                        0-2
                                                                        0-5
                       Number of Distinct Models




                                                                       0-2




                                                                                                                                    sa
                                                                          Instruction Length (tokens)                               Autonomous Steps/Cycles
                                    (a)                                                (b)                                                         (c)

 Figure 8. Overview of core components configurations and architectures in deployed Agentic AI systems: (a) Number of distinct models
 combined to solve a single logical task (N =22); (b) Distribution of prompt lengths in temrs of tokens (N =33) and (c) Number of
 autonomous execution steps before user intervention (N =60).


  tonomous cycles, reflecting more aggressive exploration of                          tems. While this figure currently includes simpler meth-
  open-ended autonomy during early development.                                       ods like composing outputs from multiple models (Sec-
                                                                                      tion 5.1), future work may determine how advanced tech-
  Practical constraints drive this design choice. Case study
                                                                                      niques—such as self-planning, search-based reasoning,
  participants identify problem complexity, non-determinism
                                                                                      and self-verification—perform in production, as these ap-
  in agent self-planning, and latency requirements as key lim-
                                                                                      proaches may then lead to higher numbers of model calls
  iting factors. Practitioners intentionally impose limits on
                                                                                      and steps before human intervention .
  reasoning steps to maintain reliability and manage compu-
  tational time and costs. This simplicity reflects a broader                          RQ2 Finding #6: Agents operate with tightly bounded
  preference for predictable, controllable workflows over ex-                          autonomy: 68% of systems execute fewer than ten steps
  perimental open-ended autonomy in production environ-                                and 46.7% with less than 5 model calls before requiring
  ment.                                                                                human intervention.
  Number of Model Calls. While distinct from logical
                                                                                      Agent Control Flow. We observe that production agents
  steps (which often include non-inference actions like tool
                                                                                      favor predefined static workflows over full open-ended au-
  execution), we specifically analyze model calls to gauge
                                                                                      tonomy. We find that 80% of our detailed case studies uti-
  the inference intensity of deployment systems. We observe
                                                                                      lize a structured control flow. These agents operate within
  that within a single subtask, deployment systems typically
                                                                                      well-scoped action spaces rather than freely exploring the
  execute model calls on the order of tens or less. The majority
                                                                                      environment to self-determine objectives.
  (66.7%) of deployed survey agents use fewer than 10 calls
  per subtask, with 46.7% using fewer than 5 calls. This is                           Detailed case studies provide insight into these control
  followed by 33.3% using tens of calls, 9.0% in the hundreds,                        flow patterns. Nine cases utilize various forms of agentic
  and 6.1% in the thousands. Interestingly, another 12.1% do                          Retrieval-Augmented Generation (RAG) pipelines, ranging
  not set explicit limits. This aligns with our detailed case                         from single agents retrieving information via tool calls to
  studies, where 3 teams confirm executing tens of model calls                        sophisticated pipelines with over 20 subtasks that explic-
  per subtask (up to 40–50 calls).                                                    itly configure retrieval at certain steps. For example, one
                                                                                      insurance agent follows a fixed sequence: coverage lookup,
  Experimental systems are far more likely to sit in the long
                                                                                      medical necessity review, and risk identification.‡ While the
  tail, with many agents routinely making tens of calls. In con-
                                                                                      agent possesses autonomy to complete each subtask (e.g.,
  trast, deployed agents concentrate in the lower-call regime,
                                                                                      deciding if a case needs human intervention for risk iden-
  suggesting that teams aggressively cap or refactor call bud-
                                                                                      tification), the high-level objective and expected output of
  gets as they move from experimentation to deployment to
                                                                                      each subtask remain fixed.
  probably control cost, latency, and failure amplification.
                                                                                      Open-ended autonomy remains rare. We observe only one
  Despite the pattern of limited model calls, 31% of de-
                                                                                           ‡
  ployed survey agents already use various inference-time                                 This is a simplified example workflow to illustrate the core
  scaling techniques, compared to 44% in experimental sys-                            logic, redacted to protect the anonymity of the interviewee.


                                                                                 10
                                               Measuring Agents in Production

case where agents operate with unconstrained exploration.                                                OpenAI Swarm
Notably, this system runs exclusively in a sandbox environ-                                   70%        LlamaIndex
                                                                                                         CrewAI                    60.7%
ment with rigorous CI/CD verification on the final outputs,                                   60%        Other                       3.6%
                                                                                                                                     3.6%




                                                                             % of Responses
avoiding direct interaction with production environment.                                                 LangChain/LangGraph
                                                                                              50%                                   10.7%
                                                                                                       39.3%
However, we identify a growing interest in expanding au-                                      40%
tonomy. Four detailed case studies employ a planning and                                                                            17.9%
routing agent to decompose input requests and dispatch
                                                                                              30%
them to task-specialized agents. Another team specializes                                     20%
                                                                                                                                    25.0%
agents into generators and verifiers, enabling greater auton-                                 10%
omy through automated verification. Several teams share
                                                                                               0%         No                         Yes
that they are experimenting with flexible workflows by al-
                                                                                                     Did Not Use               Used Framework
lowing agents to make autonomous decisions about next                                               Any Framework
steps or by using planning and orchestration agents.
                                                                      Figure 9. Frameworks reported to support critical functionality
 RQ2 Finding #7: Deployment architectures favor                       among those using open frameworks for production systems (N =
 predefined, structured workflows over open-ended au-                 29). Additional framework options were provided in the survey;
 tonomous planning to ensure reliability.                             see Appendix E.3 for the complete question and options.


5.5. Agentic Frameworks
                                                                      cies sometime prohibit the use of certain external libraries
We find a divergence in framework adoption between survey             in enterprise environments, compelling teams to develop
respondents and interview case studies. Among deployed                compliant solutions internally.
agents from the survey, two-thirds (60.7%) use third-party
agentic frameworks. Reliance concentrates around three                  RQ2 Finding #8: Framework adoption varies signifi-
primary frameworks: LangChain/LangGraph [80, 81] leads                  cantly between survey and case study. While third-party
with 25.0%, followed by CrewAI [82] at 10.7%, with LLa-                 frameworks get broad adoption in the survey (61%), in-
MAIndex [83] and OpenAI Swarm [84] both at 3.6% (Fig-                   terviewed teams predominantly build custom in-house
ure 9).                                                                 implementations (85%) to maximize control and mini-
                                                                        mize dependency bloat.
In sharp contrast, our detailed case studies reveal a strong
preference for custom in-house agent implementations.
Only 3 of 20 (15%) detailed case studies rely on external             6. RQ3 Results: How Are Agents Evaluated
agent frameworks (2 use LangChain, 1 uses BeeAI). The                    For Deployment?
remaining 17 teams (85%) build their agent application en-
tirely in-house with direct model API calls. For example,             Evaluation practices shape which agentic systems reach
one interview case explicitly shared that their agents are            production and how teams iterate on deployed systems. We
their own implementation of ReAct loops. Notably, two ad-             investigate how practitioners evaluate and test their agents to
ditional teams report starting with frameworks like CrewAI            meet production deployment requirements, examining both
during the experimental prototyping phase but migrating               offline evaluation during development and online evaluation
to custom in-house solutions for production deployment to             in production environments. Specifically, we examine two
reduce dependency overhead.                                           aspects: what practitioners compare their systems against
                                                                      (baselines and benchmarks), and what methods they use to
We identify three core motivations for building custom so-
                                                                      verify system outputs (evaluation methods).
lutions from the detailed case studies. First, flexibility and
control are critical. Deployed agents often require vertical          Our findings reveal that evaluation practices vary widely
integration with proprietary infrastructure and customized            across production agents, even within the same application
data pipelines that rigid frameworks struggle to support.             domain, shaped by the specific requirements of each de-
For example, one agent-native company deploys customer-               ployment context and the availability of ground truth data.
facing agents across varied client environments, necessi-             Notably, practitioners currently focus on agent output qual-
tating a bespoke orchestration layer. Second, simplicity              ity and correctness rather than traditional software reliability
drives the decision. Practitioners report that core agent             metrics. Based on 20 detailed case studies, no team reports
loops are straightforward to implement using direct API               applying standard production reliability metrics such as five
calls. They prefer building minimal, purpose-built scaffolds          9s availability to their agent systems. Instead, evaluation
rather than managing the dependency bloat and abstraction             centers on whether agents produce correct, high-quality re-
layers of large frameworks. Third, security and privacy poli-         sponses.

                                                                 11
                                               Measuring Agents in Production

6.1. Baselines and Benchmarks                                         6.2. Evaluation Methods
During development, teams conduct offline evaluation to               We ask participants which evaluation strategies they employ,
assess agent performance before deployment. Figure 10a                allowing multiple selections. These methods apply to both
shows that 38.7% of survey respondents compare their de-              offline evaluation during development and online evalua-
ployed agentic systems against non-agentic baselines such             tion in production environments. Four methods dominate
as existing software systems, traditional approaches, or              responses: human-in-the-loop evaluation, model-based eval-
human execution. The remaining 61.3% do not perform                   uation, rule-based evaluation (heuristics or syntactic checks),
baseline comparisons. Among these, 25.8% report their                 and cross-referencing evaluation (verification against knowl-
systems are truly novel with no meaningful baseline for               edge bases or reference datasets). The exact question and
comparison. While we do not know reasons behind why                   method descriptions appear in Appendix E.
the remaining 35.5% did not conduct the comparison, in-
                                                                      Human-in-the-loop verification. The majority (74.2%)
depth interviews reveal that baseline comparison is often
                                                                      rely on manual, human-in-the-loop evaluation (Figure 10b.
challenging even when alternatives exist. One reason is that
                                                                      These evaluations typically involve domain experts, opera-
non-agentic baselines frequently combine multiple com-
                                                                      tors, or end-users directly inspecting, testing, or validating
ponents, making systematic technical comparison difficult.
                                                                      system outputs to ensure correctness, safety, and reliability.
The HR support agent development team illustrates that
agent solution replace a baseline process combining com-              Human experts play a critical role during development for
pany document lookup, human procedures, and non-LLM                   offline evaluations. Agent developers work directly with
HR software. While outcomes such as task completion                   domain experts or target users to validate system responses.
time are measurable, isolating technical performance for              For example, medical professionals are directly involved
comparison is challenging.                                            when testing and evaluating the correctness of healthcare
                                                                      agent systems. In one case, a company even forgoes auto-
Beyond baseline comparison, teams employ benchmark
                                                                      mated evaluation methods entirely, relying instead on human
evaluations. We refer to benchmark here as a curated set of
                                                                      experts to provide feedback to hand-tune agent configura-
tasks or questions with known correct answers. Among 20
                                                                      tions for each client’s deployment environment.
teams, 5 build custom benchmarks. One team builds bench-
marks from scratch, collecting ground truth labels through            Human experts also serve as verifiers during agent execu-
collaboration with domain experts. Four teams synthesize              tion for online evaluation. Teams commonly have human
existing data to curate benchmarks, drawing from past test            experts perform final actions based on agent output, serving
cases, system logs, pull requests, and support tickets. One           as a layer of guardrails. For example, one site reliability
team also leverages public benchmarks during early develop-           engineering agent suggests actions based on analysis across
ment. The remaining 15 teams (75%) evaluate their agents              system stacks, but human experts make the final decision
without benchmark sets, using alternative methods such as             on what to execute. The agent does not directly modify the
A/B testing, user feedback, and production monitoring.                production environment.
Among the 5 teams building custom benchmarks, our inter-              Model-based evaluation. Model-based evaluation meth-
views reveal a prevalent evaluation pattern despite diverse           ods such as LLM-as-a-judge are the second most com-
domains and organizations (e.g., human resources, cloud               mon approach, used by 51.6% of respondents (Figure 10b).
infrastructure, and business analytics). Teams establish a            While this evaluation method applies for both offline de-
golden question-and-answer set, collect user interaction and          velopment time and online runtime evaluation, 7 of 20 in-
feedback data, then work with subject matter experts to               terview case studies use LLM judges for online evaluation
examine quality and expand the golden set. This process               during agent execution.
extends into production runtime, enabling LLM-as-a-judge
                                                                      Model-based evaluation does not eliminate human involve-
online evaluation pipelines. Based on our analysis, the con-
                                                                      ment. Figure 10c shows the co-occurrence of different eval-
vergence of nearly identical pipelines across diverse contexts
                                                                      uation strategies, revealing that among the 51.6% of survey
suggests research and development opportunities in reusable
                                                                      respondents who use model-based evaluation, a substantial
data ingestion pipelines, curation methods for golden sets,
                                                                      portion (38.7%) also employ Human-in-the-Loop verifica-
and synthetic generation techniques for evaluation datasets.
                                                                      tion. In detailed case studies, all interviewed teams using
 RQ3 Finding #1: Many agentic systems lack standard-                  LLM-as-a-judge combine it with human review. Specifi-
 ized benchmarks or baselines. Teams build custom eval-               cally, these teams use LLM judges to evaluate confidence
 uation frameworks from scratch, often creating ground                in every final response, combined with human subsampling.
 truth data for the first time.                                       An LLM judge continuously assesses each agent’s final
                                                                      response. If the judge scores above a preset confidence
                                                                      threshold, the output is accepted automatically. Otherwise,

                                                                 12
                                                                                Measuring Agents in Production

                 100%                                                                Manual                                                                                         70
                               Alternative does not exist              (Human in the Loop)
                                                                                                                         74.2% (23)           Manual 74.2%
                                                                                                                                                      (23)
                                                                                                                                                           38.7% 29.0% 22.6%
                                                                                                                                                            (12)  (9)   (7)
                 80%           Alternative might exist                                                                                                                              60
                                                                                Model Based                       51.6% (16)
                                                                     (e.g., LLM-as-a-Judge)                                               Model Based 38.7% 51.6% 29.0% 16.1%
% of Responses



                                                  61.3%




                                                                                                                                                                                     % of Responses
                 60%                                                                                                                                   (12)  (16)  (9)   (5)        50
                                                                          Cross-Referencing                   41.9% (13)
                           38.7%                 35.5%      (e.g., RAG, Knowledge Graphs)
                 40%                                                              Rule Based                                          Cross-Referencing 29.0%
                                                                                                                                                         (9)
                                                                                                                                                              29.0% 41.9% 16.1%
                                                                                                                                                               (9)   (13)  (5)
                                                                                                                                                                                    40
                                                                                                            38.7% (12)
                                                                       (e.g., Syntax Checks)                                                                                        30
                 20%
                                                 25.8%                  None of the above       3.2% (1)                                   Rule Based 22.6%
                                                                                                                                                       (7)
                                                                                                                                                            16.1% 16.1% 38.7%
                                                                                                                                                             (5)   (5)   (12)       20
                  0%         Yes                   No                                      0%   20% 40% 60% 80% 100%
                        Compared to              Did Not




                                                                                                                                                     al

                                                                                                                                                            ed




                                                                                                                                                                               ed
                                                                                                                                                                      g
                                                                                                                                                                    cin
                                                                                                                                                   nu
                                                                                                       % of Responses




                                                                                                                                                          as




                                                                                                                                                                             as
                         Alternative            Compare




                                                                                                                                                 Ma




                                                                                                                                                                  en
                                                                                                                                                          lB




                                                                                                                                                                            le B
                                                                                                                                                                fer
                                                                                                                                                       de




                                                                                                                                                                        Ru
                                                                                                                                                               Re
                                                                                                                                                     Mo

                                                                                                                                                            ss-
                                                                                                                                                          Cro
                                       (a)                                                                  (b)                                                       (c)

 Figure 10. Evaluation Practices in Agentic AI Systems: (a) Comparison to Alternatives: Shows whether participants explicitly compared
 their deployed agent against a non-agentic baseline (e.g., existing software, traditional workflows, etc). (b) Evaluation Methods
 Distribution: Distribution of evaluation methods reported by practitioners (N =31). The question was multi-select, so respondents could
 choose multiple methods. (c) Evaluation Strategies Co-occurrence: Visualizes the pairwise overlap between evaluation strategies. Manual
 human-in-the-loop evaluation has the highest overlap with other strategies, suggesting that teams commonly rely on manual review to
 complement automated checks.


  the request routes to human experts. Additionally, human                                                  source operations demand expertise beyond pattern match-
  experts sample a preset percentage (e.g., 5%) of production                                               ing, explaining why practitioners require human and LLM
  runs even when the LLM judge expresses high confidence,                                                   verification to assess output correctness.
  verifying correctness to ensure consistent alignment at run-
  time. Development teams update prompt instructions and                                                      RQ3 Finding #2: Human judgment dominates evalua-
  agent configurations based on this production feedback.                                                     tion (74.2%). LLM-as-a-judge emerges as a complemen-
                                                                                                              tary automated approach (51.6%), typically combined
 Other methods. Rule-based evaluation methods and                                                             with human verification.
 cross-referencing strategies show comparable adoption rates
 (41.9% and 38.7% respectively). Rule-based evaluation con-
 sists of simple logic checks such as grammar and syntax                                                    7. RQ4 Results: What Are The Top
 verification or domain-specific rules. For example, coding                                                    Challenges In Building Production Agents?
 agents verify outputs through compilation checks and test
 suites, while analytical agents may apply domain-specific                                                  AI agents are deployed at scale, yet significant challenges
 rubrics to assess output quality. Cross-referencing evalua-                                                remain. We investigate the friction points practitioners face
 tion uses external sources for grounding and fact-checking                                                 most when building production agents. Our survey and
 to verify the accuracy and quality of generated answers                                                    detailed case studies reveal that reliability remains the pri-
 or solutions. This includes retrieving supporting evidence                                                 mary bottleneck. Survey respondents at all agent stages rank
 from trusted knowledge bases or comparing outputs against                                                  “Core Technical Focus” as their top challenge (37.9%), far
 reference datasets.                                                                                        outweighing governance (3.4%) or compliance (17.2%) (see
                                                                                                            Appendix B.3). Core technical focus encompasses reliabil-
  Evaluation method patterns. Co-occurrence analysis re-                                                    ity, robustness, and scalability. This prioritization signals
  veals that human-in-the-loop evaluation is the most common                                                that practitioners currently focus on making agents work
  method used together with other evaluation strategies (Fig-                                               consistently and correctly.
  ure 10c). Practitioners anchor automated, rule-based, and
  cross-referencing methods around human judgment rather                                                      RQ4 Finding #1: Reliability remains unsolved. It
  than relying on them in isolation.                                                                          represent the top development focus for agents in all
 Notably, human-in-the-loop (74.2%) and LLM-as-a-judge                                                        stages including ones in deployment.
 (51.6%) dominate compared to rule-based verification                                                       We detail the three specific dimensions of these challenges:
 (42.9%). Based on our analysis, this pattern may suggests                                                  evaluation (Section 7.1), latency (Section 7.2), and security
 that production agents already handle complex tasks be-                                                    (Section 7.3). This gap highlights research opportunities
 yond classification, entity resolution, or pattern matching.                                               to advance agents from bounded use cases toward broader
 These agents operate in domains requiring nuanced judg-                                                    applications.
 ment where rule-based methods prove insufficient. For
 example, customer support voice assistance and human re-

                                                                                                       13
                                                Measuring Agents in Production

7.1. Evaluation Challenges
                                                                                     Latency Blocker           14.8% (4)
Difficulties creating benchmarks. As defined in Sec-
tion 6.1, benchmarks are curated sets of tasks or questions             Deployable with Latency Gap                             59.3% (16)
with known correct answers used for offline evaluation dur-
                                                                                 No Latency Concern                 25.9% (7)
ing development. Among interviewed teams, 5 build custom
benchmarks. However, benchmark creation proves challeng-                                            0% 20% 40% 60% 80% 100%
ing for three reasons based on our case study interviews.                                                      % of Responses
First, specific domains lack accessible public data. In reg-           Figure 11. Degree to which latency causes problems for deploy-
ulated fields like insurance underwriting, the absence of              ment of Agentic AI systems (N = 27). These responses suggest
public data forces teams to handcraft benchmark datasets               that latency is rarely a strict blocker for deploying most agentic AI
from scratch through collaboration with domain experts                 systems.
and target users. Second, creating high-quality benchmarks
at scale is resource-intensive and time-consuming. One
interviewed team reported spending months creating an ini-
tial set of approximately 40 unique environment-problem-               shows agents target productivity gains because end-to-end
solution scenarios, followed by another six months to scale            time and human hours quantify straightforwardly. Applica-
the dataset to roughly 100 examples. Third, benchmark                  tions with harder-to-measure benefits remain less explored.
creation is nearly infeasible for agent applications focused           For example, we observe fewer cases of agents reducing
on highly customized client integrations. One interviewed              cross-domain knowledge needs or mitigating risks, poten-
voice agent team illustrates this challenge: while core fea-           tially because benefits manifest indirectly or over longer
tures are straightforward to test without extensive data,              timeframes.
the primary engineering effort involves client-specific cus-
tomizations such as proprietary toolsets, product offerings,           7.2. Latency Challenges
and localized dialogue tuning. Creating standardized bench-            We examine the degree to which agent execution latency
marks for every possible client configuration is impractical.          hinders deployment. Survey results indicate that latency rep-
Given these challenges, 75% of interviewed teams forgo                 resents a manageable friction rather than a hard stop for most
benchmark creation entirely, instead relying on A/B test-              teams. Figure 11 shows that only 14.8% of deployed survey
ing or direct client collaboration to iterate based on human           agents identify latency as a critical deployment blocker re-
feedback until expectations are met.                                   quiring immediate resolution, while the majority (59.3%)
Agent behavior breaks traditional software testing.                    report it as a marginal issue, where current latency is subop-
Three case study teams report attempting but struggling                timal but sufficient for deployment. We suspect that this tol-
to integrate agents into existing CI/CD pipelines. The chal-           erance may correlates with the prevalence (15/20 in detailed
lenge stems from agent nondeterminism and the difficulty of            interview case studies) of asynchronous agent execution
judging outputs programmatically. Despite having various               paradigm (Section 4.4) and (52.2% from survey) internal
forms of existing regression tests from baseline systems,              user bases (Section 4.3). Notably, we observe a consistent
these teams have not yet identified effective methods to               latency distribution across the full survey dataset, including
adapt them for nondeterministic agent behavior to create               experimental systems (Figure 19b). We believe this con-
test set that cover sufficient runtime scenarios with different        sistency signals a broader preference for building offline
nuances.                                                               agents, as discussed in Section 4.4.

Verification mechanisms and benefit quantification.                    Interactive agent latency requirements. While latency
Based on the interview case studies, we observe that agent             is not a critical challenge for most agent applications, it
faces two broader evaluation challenges. First, robust ver-            remains a critical bottleneck for real-time interactive agents.
ification mechanisms do not always exist. Coding-related               Two interviewed teams, building voice and specialized chat
agents benefit from strong correctness signals through com-            agents, report continuous engineering efforts to match hu-
pilation and test suites, such as software migration agents            man conversational speeds. Unlike asynchronous work-
and site reliability agents in Table 1. However, many agents           flows, these systems require seamless turn-taking where de-
operate in settings without robust and fast verification. For          lays disrupt the user experience. Achieving fluid real-time
example, insurance agents receive true signals only through            responsiveness beyond rigid turn-based exchanges remains
real consequences such as financial losses or delayed patient          an open research question and development challenge.
approvals. These signals arrive slowly and in forms difficult          Practical latency management. Interview participants de-
to automate for evaluation. Second, the final benefits of              scribe two approaches to managing latency. First, teams
using agents are not always easy to measure. Section 4.1               commonly implement hard limits on maximum steps or

                                                                  14
                                                   Measuring Agents in Production

                                                                           four approaches to managing security risks through con-
            Database                                 89.7% (26)
                                                                           strained agent design. First, six teams restrict agents to
   Confidential data                             69.0% (20)                “read-only” operations to prevent state modification. For
       Live user data                          65.5% (19)                  example, one SRE agent case study generate bug reports
                                                                           and proposes action plans, but leaves the final execution
  Live non-user data                      51.7% (15)
                                                                           to human engineers. Second, three teams deploy agents in
  Public online data                  34.5% (10)                           sandboxed or simulated environments to isolate live sys-
                    0%   20% 40% 60% 80% 100%                              tems. In one instance, a code migration agent generates
                               % of Responses                              and tests changes in a mirrored sandbox, merging code only
                                                                           after software verification. Third, one team builds an ab-
Figure 12. Overview of data handling capabilities: Types and               straction layer between agents and production environments.
modes of data ingestion and handling in deployed agent systems             This team constructs wrapper APIs around production tools,
(N =29). The question was multi-select i.e., allowing participants         restricting the agent to this intermediate layer and hiding
to indicate all/any data handling methods currently integrated into        internal function details. Finally, one team attempt to en-
their deployed agentic systems. The data illustrates how agents            force role-based access controls that mirror agent user’s
source information, showing a strong reliance on internal infras-          permissions. However, the agent team reports this remains
tructure over public sources.
                                                                           challenging, as agents can bypass these configurations when
                                                                           accessing tools or documents with conflicting fine-grained
                                                                           permissions.
model inference calls, typically derived from heuristics. Sec-
ond, one team adopts a creative solution by pre-building
a database of request types and agent actions (tool calls),                8. Discussion
then employing semantic similarity search at runtime to                    Building on the quantitative findings in Sections 4–7, we
identify similar requests and serve prebuilt actions, reducing             discuss three key trends that characterize the current state
response times by orders of magnitude compared to rea-                     of agent engineering. We first examine how practition-
soning and generating new responses. These workarounds                     ers achieve production reliability through architectural con-
demonstrate that practitioners currently rely on system-level              straints (Section 8.1). Next, we highlight how current model
engineering to bypass the inherent latency costs of founda-                capabilities already drive substantial value, revealing ad-
tion models.                                                               ditional adoption opportunities (Section 8.2). Finally, we
                                                                           outline concrete open research directions for agent develop-
7.3. Security and Privacy Challenges                                       ment (Section 8.3).
Security and privacy consistently rank as secondary con-
cerns in both of our survey and interviews, with practition-               8.1. Reliability Through Constrained Deployment
ers prioritizing output quality and correctness. Figure 21a                A paradox emerges from our data: while nearly 40% of
shows that Compliance and User Trust ranks fourth among                    practitioners identify reliability, robustness, and scalability
challenge categories. Given that Section 4.3 shows 52.2%                   as their primary development concern (Section 7), these sys-
of systems serve internal employees and many systems with                  tems have successfully reached deployments in production
human supervision, this prioritization reflects current de-                or pilot stages (Section 4). This raises a critical question:
ployment environments and requirements rather than dis-                    how do agents reach production if reliability remains an
missing security’s importance.                                             unsolved challenge? We observe that practitioners ensure
Data ingestion and handling. Survey results in Fig-                        reliability via deploying agents with strict constraints on
ure 12 show that 89.7% of systems ingest information from                  both execution environments and agent autonomy, often
databases, 65.5% ingest real-time user input, and 51.7%                    combined with close human supervision.
ingest other real-time signals. Notably, 69.0% of systems                  Our in-depth case studies reveals several deployment envi-
retrieve confidential or sensitive data, while only 34.5%                  ronment patterns. Some agents operate in read-only mode,
retrieve persistent public data. Given the high prevalence                 never modifying production state directly. For example,
of sensitive data usage and user inputs, preserving privacy                SRE agents perform debugging then generate detailed bug
is critical. Our interview case studies reveal that teams                  reports that engineers review and action. Other agents serve
address this through legal methods. For example, a team                    internal users where errors carry lower consequences and
building healthcare agents report relying on standard data-                human experts remain readily available to correct mistakes
handling practices and strict contractual agreements with                  (Section 4.3): for example, Slack bot response automa-
model providers to prevent training on their user data.                    tion for internal tickets. Systems with write access de-
Security practices. In-depth interview participants describe               ploy through sandbox environments where outputs undergo

                                                                      15
                                               Measuring Agents in Production

rule-based verification before production integration. Some                                               Modalities Currently Supports




                                                                                                                                                                93.1%
teams combine read-only access with sandboxes mirroring                                 100%              Modalities to Support in Future




                                                                                                                                                                           82.8%
production environments to further mitigate risk. We ob-




                                                                       % of Responses
                                                                                        80%




                                                                                                                                                     65.5%




                                                                                                                                                                              60.9%
serve that these patterns shift the reliability challenge from




                                                                                                                        52.2%
                                                                                        60%




                                                                                                                                   47.8%




                                                                                                                                                        43.5%
ensuring correct autonomous agent actions at each step to




                                                                                                                                             41.4%




                                                                                                                                                                   39.1%
                                                                                                                                37.9%


                                                                                                                                           34.8%
                                                                                                 30.4%
verifying that final outputs meet acceptable quality thresh-                            40%




                                                                                                             26.1%
                                                                                                                     20.7%
olds.




                                                                                                         13.8%
                                                                                        20%




                                                                                               6.9%
Section 5.4 shows 68% of production agents execute fewer
than ten steps before requiring human intervention. Organi-                              0%




                                                                                                                  es
                                                                                           Ge Scie deos




                                                                                            tur abul e
                                                                                                       l te ta




                                                                                             Ma angu ata
                                                                                                           ag ral




                                                                                                    t e ne t
                                                                                                          , lo ed
                                                                                                tex e ge Tex
                                                                                                                  d
zations deliberately bound agent behavior within specific ac-




                                                                                                    tia da



                                                                                                               ag

                                                                                                              Co




                                                                                                       .g. rat
                                                                                                               es




                                                                                                              gs
                                                                                                       Im mpo




                                                                                                  L ar d
                                                                                                           Im
                                                                                                            Vi




                                                                                                   in e
                                                                                                  pa fic




                                                                                                ch ag
tion spaces through prompting and limited tooling. External-




                                                                                              os nti




                                                                                                    T
facing systems use particularly restricted agent workflows




                                                                                               al
where customer trust and economic consequences demand




                                                                                         Na
tighter control. For example, rather than allowing an agent                                                                       Modalities
to autonomously decide if and where to search via tool
call, teams employ agentic RAG architectures with pre-                Figure 13. Data modalities already supported (red) versus modali-
determined retrieval steps that restrict the agent to specific        ties planned for future support (blue) in production agent systems
document store. We believe this pattern reveals a deliberate          (N =29). Bars to the left of the dashed line indicate modalities
engineering trade-off. Production teams balance capability            with expected increases in future support, whereas modalities to
with controllability such that these systems deliver value            the right are already widely supported with limited planned expan-
through well-scoped automation while maintaining reliabil-            sion. Interestingly, the modalities with the largest planned growth
ity guarantees.                                                       are all non-textual, pointing toward increasingly multimodal agent
                                                                      systems.
An open question remains: how can future agents expand au-
tonomy while maintaining production-level reliability? The
field has not established clear pathways for systematically
relaxing these constraints while preserving safety guaran-            This data pattern demonstrates that practitioners enable sub-
tees. We observe that one emerging pattern to achieve this            stantial deployment by leveraging existing model capabili-
goal is the merging of distinct subtasks into a single task.          ties within well-scoped applications rather than waiting for
For example, commercial coding assistants adopt test-driven           model improvements. We already see diverse implementa-
development by merging coding and testing into a unified              tions where agents support healthcare workflows, manage
agent execution flow [16, 85]. We believe this pattern of             business operations, and accelerate scientific discovery in
decoupling logical task abstraction from agent execution              production (Table 1).
steps has potential to extend to other domains. The way hu-           Figure 5a and our case interviews reveal that relatively little
mans break down tasks into subtasks might not be the right            attention has been given to applying agents to software-
way to organize agent control flow (Figure 22). Progress              facing rather than human-facing problems. Most production
requires advances in two areas: agent evaluation must move            agents interface directly with users through chat, voice, or
beyond correctness metrics to assess other aspects of reli-           interactive workflows. We observe fewer deployments for
ability (e.g.: five 9s) under varying autonomy levels, and            direct software operation, maintenance, and optimization
engineering practices that systematically specify and verify          tasks. We believe opportunities to improve automation in
bounded operations at different abstraction levels.                   these software-integrated systems remain under-explored,
                                                                      though realizing this potential requires addressing the relia-
8.2. Rich Agent Application Opportunities                             bility challenges discussed in Section 8.1.
Our study reveals an encouraging finding: production agents
already operate across more than 26 domains (Figure 2),               8.3. Open Research Questions
extending well beyond coding-related agents and chatbots.             Beyond the directions we highlight in prior sections, we
We find that practitioners extract real value from current            identify additional research questions based on deployment
model and agent capabilities (Figure 1).                              patterns in RQ1–4.
Our detailed case studies show that current frontier models,          We show that agents often operate without clean and fast cor-
utilizing prompting strategies alone, already possess suf-            rectness signals in the real-world (Section 7.1). We observe
ficient capabilities to cover a diverse range of production           an analogy with silent failures, where catching errors during
use cases. Section 5.1 shows that 70% of deployed survey              runtime is challenging and success signals arrive through
agents rely on off-the-shelf models without any fine-tuning.          real consequences like financial loss or customer dissatis-

                                                                 16
                                               Measuring Agents in Production

faction. Engineers dedicate substantial effort ensuring agent         9. Conclusion
quality through close human oversight, demonstrating effec-
tive practices that enable current deployments. However, the          We present MAP, the first large-scale systematic study char-
field has yet to reach consensus on effective ways to identify        acterizing the engineering practices and technical methods
what and when errors or low-quality responses occur. We               behind AI agents actively deployed in production. We an-
believe understanding agent failure modes [86], develop-              alyze data from agent practitioners across 26 domains to
ing agent observability tools, and advancing runtime failure          answer four research questions regarding the state of real-
mitigation techniques represent important open research di-           world agent development:
rections in addition to benchmarking and CI/CD integration
(Section 7.1).
                                                                      • RQ1: Why build agents? Productivity drives adoption.
Significant evidence shows interest in post-training for                Organizations deploy agents primarily to automate routine
agents [6, 87–93], yet Section 5.1 shows fine-tuning and                tasks and reduce human task hours, prioritizing measur-
reinforcement learning remain uncommon in deployment                    able efficiency gains over novel capabilities.
despite potential benefits. Our interviews reveal develop-
ment effort currently prioritizes making agents work reliably
over improving model capabilities for preference optimiza-            • RQ2: How are agents built? Simplicity and controlla-
tion, specialization, or cost trade-offs. We speculate this             bility dominate. Production systems favor closed-source
pattern emerges for two reasons: first, supervised fine-tuning          models utilizing manual prompting rather than weight
and reinforcement learning impose barriers to entry, requir-            tuning. Architecturally, these systems rely on structured
ing large amounts of representative data or environments                workflows with bounded autonomy and typically execute
alongside with specialized ML expertise; second, model up-              limited steps before human intervention.
grades introduce complexity when fine-tuned models must
adapt to new base versions. We believe the field needs more           • RQ3: How are agents evaluated? Human verification
sample-efficient post-training approaches that remain robust            remains the primary method. Practitioners rely heavily on
to model upgrades and translate into repeatable engineering             human-in-the-loop evaluation because clean baselines and
practices.                                                              ground truth datasets are scarce. Automated techniques
We find in Section 5.4 that 30% of deployed survey agents               like LLM-as-a-judge complement human review rather
already adopt inference-time scaling techniques, with the               than replace it.
use of multiple models being most popular. From detailed
case studies, we find these are commonly simple meth-
                                                                      • RQ4: What are the challenges? Reliability represents
ods, such as routing distinct subtasks to specialized models.
                                                                        the central development focus. The difficulty of ensuring
We believe recent advances in generate-verify-search ap-
                                                                        correctness and evaluating non-deterministic agent out-
proaches [10, 94] have significant potential for non-science
                                                                        puts drives this friction. Latency and security typically
agent applications as well because they provide stronger
                                                                        act as manageable constraints rather than hard blockers
reliability guarantees while maintaining controllability and
                                                                        as engineering workarounds and restricted environments
explainability. However, realizing this potential may re-
                                                                        currently manage them.
quires infrastructural support and redesign, such as building
simulators and designing verifier. How to adapt agent run-
time environments to support such inference-time search               As “agent engineering” emerges into a new discipline, MAP
technique, and how to effectively utilize them in an online           provides researchers with critical visibility into real-world
execution settings, are open research questions.                      constraints and opportunities while offering practitioners
We show in Figure 13 that 93% of current production agents            proven deployment patterns across industries.
take text or speech in natural language as inputs. Both
our survey trends and interviews show high interest in ex-            Acknowledgements
panding agent modalities to include images, spatiotemporal
sequences, video, and scientific data. Interview participants         We thank our many anonymous participants without whom
suggest that teams currently focus on applications that are           beginning this study would not be possible. This research
easy to measure and validate. We believe that once these              was supported by gifts from Accenture, Amazon, AMD,
initial deployments work reliably, agent features and capa-           Anyscale, Broadcom Inc., Google, IBM, Intel, Intesa San-
bilities will expand to handle richer input modalities.               paolo, Lambda, Mibura Inc, Samsung SDS, and SAP. We
                                                                      also thank Alex Dimakis, Drew Breunig, Tian Xia, and
                                                                      Shishir Patil for their valuable feedback and insightful dis-
                                                                      cussions.

                                                                 17
                                           Measuring Agents in Production

References                                                           Jongseok Park, Shuo Yang, Jeff Chen, Lakshya
                                                                     Agrawal, Aditya Desai, Jiarong Xing, Koushik Sen,
 [1] Lilian Weng. Llm powered autonomous agents. URL
                                                                     Matei Zaharia, and Ion Stoica. Barbarians at the gate:
     https://lilianweng.github.io/posts
                                                                     How ai is upending systems research, 2025. URL
     /2023-06-23-agent/.
                                                                     https://arxiv.org/abs/2510.06189.
 [2] OpenAI. Agents — openai api docs. URL https:
                                                                [11] Parshin Shojaee, Kazem Meidani, Shashank Gupta,
     //platform.openai.com/docs/guides/
                                                                     Amir Barati Farimani, and Chandan K Reddy. Llm-
     agents.
                                                                     sr: Scientific equation discovery via programming
 [3] Google Cloud. What are ai agents? definition, exam-             with large language models, 2025. URL https:
     ples, and types. URL https://cloud.google                       //arxiv.org/abs/2404.18400.
     .com/discover/what-are-ai-agents.
                                                                [12] Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Fo-
 [4] IBM. What are ai agents? URL https://www.ib                     erster, Jeff Clune, and David Ha. The ai scientist:
     m.com/think/topics/ai-agents.                                   Towards fully automated open-ended scientific discov-
                                                                     ery, 2024. URL https://arxiv.org/abs/24
 [5] Tanay Varshney. Introduction to llm agents. URL                 08.06292.
     https://developer.nvidia.com/blog/
     introduction-to-llm-agents/.                               [13] Juraj Gottweis, Wei-Hung Weng, Alexander Daryin,
                                                                     Tao Tu, Anil Palepu, Petar Sirkovic, Artiom
 [6] Kexin Huang, Serena Zhang, Hanchen Wang, Yuan-                  Myaskovsky, Felix Weissenberger, Keran Rong, Ryu-
     hao Qu, Yingzhou Lu, Yusuf Roohani, Ryan Li, Lin                taro Tanno, Khaled Saab, Dan Popovici, Jacob Blum,
     Qiu, Gavin Li, Junze Zhang, Di Yin, Shruti Mar-                 Fan Zhang, Katherine Chou, Avinatan Hassidim, Bu-
     waha, Jennefer N. Carter, Xin Zhou, Matthew Wheeler,            rak Gokturk, Amin Vahdat, Pushmeet Kohli, Yossi Ma-
     Jonathan A. Bernstein, Mengdi Wang, Peng He, Jing-              tias, Andrew Carroll, Kavita Kulkarni, Nenad Toma-
     tian Zhou, Michael Snyder, Le Cong, Aviv Regev, and             sev, Yuan Guan, Vikram Dhillon, Eeshit Dhaval Vaish-
     Jure Leskovec. Biomni: A general-purpose biomed-                nav, Byron Lee, Tiago R D Costa, José R Penadés,
     ical ai agent. bioRxiv, 2025. doi: 10.1101/2025.05.             Gary Peltz, Yunhan Xu, Annalisa Pawlosky, Alan
     30.656746. URL https://www.biorxiv.org/                         Karthikesalingam, and Vivek Natarajan. Towards an
     content/early/2025/06/02/2025.05.30.                            ai co-scientist, 2025. URL https://arxiv.org/
     656746.                                                         abs/2502.18864.
 [7] Kyle Swanson, Wesley Wu, Nash L. Bulaong, John E.
                                                                [14] Yutaro Yamada, Robert Tjarko Lange, Cong Lu, Shen-
     Pak, and James Zou. The virtual lab of ai agents
                                                                     gran Hu, Chris Lu, Jakob Foerster, Jeff Clune, and
     designs new sars-cov-2 nanobodies. Nature, 646:716–
                                                                     David Ha. The ai scientist-v2: Workshop-level au-
     723, July 2025. doi: 10.1038/s41586-025-09442-9.
                                                                     tomated scientific discovery via agentic tree search,
     URL https://www.nature.com/articles/
                                                                     2025. URL https://arxiv.org/abs/2504
     s41586-025-09442-9.
                                                                     .08066.
 [8] Sizhe Liu, Yizhou Lu, Siyu Chen, Xiyang Hu, Jieyu
                                                                [15] Cursor Inc. Cursor: AI Coding Assistant. https:
     Zhao, Yingzhou Lu, and Yue Zhao. Drugagent:
                                                                     //www.cursor.com/, 2024. Accessed: 2025-09-
     Automating ai-aided drug discovery programming
                                                                     30.
     through llm multi-agent collaboration, 2025. URL
     https://arxiv.org/abs/2411.15692.                          [16] Anthropic. Claude code: Agentic code assistant. ht
                                                                     tps://www.anthropic.com/, 2025. Accessed:
 [9] Alexander Novikov, Ngân Vũ, Marvin Eisenberger,
                                                                     2025-09-30.
     Emilien Dupont, Po-Sen Huang, Adam Zsolt Wag-
     ner, Sergey Shirobokov, Borislav Kozlovskii, Fran-         [17] OpenAI. Openai codex. https://openai.c
     cisco J. R. Ruiz, Abbas Mehrabian, M. Pawan Ku-                 om/index/introducing-codex/, 2025. Ac-
     mar, Abigail See, Swarat Chaudhuri, George Holland,             cessed: 2025-09-30.
     Alex Davies, Sebastian Nowozin, Pushmeet Kohli,
     and Matej Balog. Alphaevolve: A coding agent               [18] Windsurf. Windsurf. https://windsurf.com/,
     for scientific and algorithmic discovery, 2025. URL             2025. Accessed: 2025-09-30.
     https://arxiv.org/abs/2506.13131.
                                                                [19] IACPM and McKinsey. Emerging generative ai use
[10] Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li,                  cases in credit: Research results, March 2025. URL
     Bowen Wang, Alex Krentsel, Tian Xia, Mert Cemri,                https://iacpm.org/wp-content/uploa

                                                           18
                                             Measuring Agents in Production

     ds/2025/03/IACPM-McKinsey-Gen-AI-W                            [26] Everest Group. Agentic ai in insurance 2025, Septem-
     ebinar- 2025.pdf. Deck dated March 2025;                           ber 2025. URL https://www2.everestgr
     summarizes 2024 interviews and a December 2024                     p.com/report/egr-2025-41-r-7520/. In-
     flash survey of 44 unique institutions.                            cludes a use-case prioritization matrix (impact vs. ease)
                                                                        and guidance on where to start and how to scale.
[20] Alexander Verhagen, Angela Luget, Olivia Conjeaud,
     Vasiliki Stergiou, and Debanjan Banerjee. How agentic         [27] Emma Linsenmayer. Leveraging artificial intelligence
     ai can change the way banks fight financial crime,                 to support students with special education needs. Tech-
     August 2025. URL https://www.mckinsey.c                            nical Report 46, OECD, September 2025. URL
     om/capabilities/risk-and-resilienc                                 https://www.oecd.org/content/dam/o
     e/our-insights/how-agentic-ai-can-c                                ecd/en/publications/reports/2025/0
     hange-the-way-banks-fight-financial                                9/leveraging-artificial-intelligenc
    -crime. McKinsey & Company article.                                 e-to-support-students-with-special
                                                                       -education-needs_ebc80fc8/1e3dffa9
[21] Capgemini. Banks and insurers deploy ai agents to                 -en.pdf. Working paper.
     fight fraud and process applications, with plans for
                                                                   [28] Sandeep Kakar, Pratyusha Maiti, Karan Taneja,
     new roles to supervise the ai, November 2025. URL
                                                                        Alekhya Nandula, Gina Nguyen, Aiden Zhao, Vrinda
     https://www.capgemini.com/us-en/ne
                                                                        Nandan, and Ashok Goel. Jill watson: Scaling and
     ws/press-releases/banks-and-insurer
                                                                        deploying an ai conversational agent in online class-
     s-deploy-ai-agents-to-fight-fraud
                                                                        rooms. In Proceedings of the 20th International Con-
    -and-process-applications-with-pla
                                                                        ference on Intelligent Tutoring Systems (ITS 2024),
     ns-for-new-roles-to-supervise-the
                                                                        2024. URL https://dilab.gatech.edu/t
    -ai/. Press release.
                                                                        est/wp-content/uploads/2024/05/ITS
[22] Prakul Sharma, Val Srinivas, and Abhinav Chauhan.                  2024_JillWatson_paper.pdf. To appear in
     How banks can supercharge intelligent automation                   ITS 2024 proceedings.
     with agentic ai. URL https://www.deloitte                     [29] Michigan Ross School of Business. Google public sec-
     .com/us/en/insights/industry/finan                                 tor helps enhance learning at the university of michi-
     cial-services/agentic-ai-banking.h                                 gan with pioneering new agentic ai virtual teaching
     tml. Deloitte Center for Financial Services; article,              assistant, April 2025. URL https://michigan
     15-min read.                                                       ross.umich.edu/news/google-public-s
                                                                        ector-helps-enhance-learning-unive
[23] Allianz SE. When the storm clears, so should the claim
                                                                        rsity-michigan-pioneering-new-agent
     queue, November 2025. URL https://www.al
                                                                        ic-ai. School News / press release.
     lianz.com/en/mediacenter/news/arti
     cles/251103-when-the-storm-clears-s                           [30] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang,
     o-should-the-claim-queue.html. Allianz                             Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang,
     Media Center article.                                              Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei,
                                                                        and Jirong Wen. A survey on large language model
[24] Economist Impact. Underwriting the future: the role of             based autonomous agents. Frontiers of Computer Sci-
     artificial intelligence in insurance, 2025. URL https:             ence, 18(6), March 2024. ISSN 2095-2236. doi:
     //assets.ctfassets.net/9crgcb5vlu4                                 10.1007/s11704-024-40231-1. URL http://dx.d
     3/2X4wMqL2pYjxzZaldIpwyj/a1a54dab0                                 oi.org/10.1007/s11704-024-40231-1.
     e338b6d59953f0da377e1d2/underwriti
     ng_the_future_the_role_of_artifici                            [31] Nestor Maslej, Loredana Fattorini, Raymond Per-
     al_intellifence_in_insurance_round                                 rault, Yolanda Gil, Vanessa Parli, Njenga Kariuki,
     table_summary_report.pdf. Roundtable                               Emily Capstick, Anka Reuel, Erik Brynjolfsson, John
     summary report; sponsored by SAS.                                  Etchemendy, Katrina Ligett, Terah Lyons, James
                                                                        Manyika, Juan Carlos Niebles, Yoav Shoham, Russell
[25] KPMG. Intelligent insurance: A blueprint for creating              Wald, Tobi Walsh, Armin Hamrah, Lapo Santarlasci,
     value through ai-driven transformation, March 2025.                Julia Betts Lotufo, Alexandra Rome, Andrew Shi, and
     URL https://kpmg.com/kpmg-us/conten                                Sukrut Oak. Artificial intelligence index report 2025.
     t/dam/kpmg/pdf/2025/us-insurance-r                                 Technical report, AI Index Steering Committee, Stan-
     eport-final.pdf. Landing page for the U.S.                         ford Institute for Human-Centered Artificial Intelli-
     report; downloadable PDF dated March 2025.                         gence (HAI), Stanford University, April 2025. URL

                                                              19
                                              Measuring Agents in Production

     https://hai.stanford.edu/assets/fi                              [40] PagerDuty. Agentic ai survey 2025. PagerDuty Report,
     les/hai_ai_index_report_2025.pdf. AI                                 March 2025. URL https://www.pagerduty.
     Index Report.                                                        com/assets/Agentic-AI-Survey-Repor
                                                                          t_FINAL.pdf. Survey by Wakefield Research of
[32] Capgemini Research Institute. Rise of agentic ai: How                1,000 IT and business executives (U.S., U.K., Aus-
     trust is the key to human-ai collaboration, 2025. URL                tralia, Japan) conducted Feb 27–Mar 6, 2025.
     https://www.capgemini.com/gb-en/in
     sights/research-library/ai-agents/.                             [41] Alexander Sukharevsky, Dave Kerr, Klemens Hjartar,
     Capgemini Research Library landing page for the re-                  Lari Hämäläinen, Stéphane Bout, and Vito Di Leo.
     port.                                                                Seizing the agentic ai advantage, June 2025. URL
                                                                          https://www.mckinsey.com/capabilit
[33] PwC. Pwc’s ai agent survey. Tech Effect: AI                          ies/quantumblack/our-insights/seiz
     & Analytics, PwC US, May 2025. URL https:                            ing-the-agentic-ai-advantage. 28-page
     //www.pwc.com/us/en/tech-effect/ai                                   report. With contributions from Guillaume Dagorret.
    -analytics/ai-agent-survey.html. Sur-
     vey of 308 US executives conducted Apr 22–28, 2025.             [42] 2025: The year the frontier firm is born, April 2025.
                                                                          URL https://assets-c4akfrf5b4d3f4b7.
[34] Tianci Xue, Weijian Qi, Tianneng Shi, Chan Hee Song,                 z01.azurefd.net/assets/2025/04/WTI
     Boyu Gou, Dawn Song, Huan Sun, and Yu Su. An                        -2025-04-The-Year-the-Frontier-v13
     illusion of progress? assessing the current state of web             _68535917c7c2a.pdf. Global study combining
     agents, 2025. URL https://arxiv.org/abs/                             surveys of 31,000 workers in 31 countries, LinkedIn
     2504.01382.                                                          labor-market trends, and Microsoft 365 productivity
                                                                          signals.
[35] Reuters Staff. Over 40% of agentic ai projects will
     be scrapped by 2027, gartner says, June 2025. URL               [43] LangChain. State of ai agents, 2024. URL https:
     https://www.reuters.com/business/o                                   //www.langchain.com/stateofaiagents.
     ver-40-agentic-ai-projects-will-b                                    Survey of 1,300+ professionals on agent adoption, use
     e-scrapped-by-2027-gartner-says-202                                  cases, controls, and challenges.
     5-06-25/. Reuters, citing Gartner forecast.
                                                                     [44] Naveen Krishnan. Ai agents: Evolution, architecture,
[36] Pradyumna Shome, Sashreek Krishnan, and Sauvik                       and real-world applications, 2025. URL https://
     Das. Why johnny can’t use agents: Industry aspira-                   arxiv.org/abs/2503.12687.
     tions vs. user realities with ai agent software, 2025.
     URL https://arxiv.org/abs/2509.145                              [45] Bang Liu, Xinfeng Li, Jiayi Zhang, Jinlin Wang, Tan-
     28.                                                                  jin He, Sirui Hong, Hongzhang Liu, Shaokun Zhang,
                                                                          Kaitao Song, Kunlun Zhu, Yuheng Cheng, Suyuchen
[37] MIT Media Lab and NANDA Initiative. Nanda: The                       Wang, Xiaoqiang Wang, Yuyu Luo, Haibo Jin, Peiyan
     internet of ai agents. URL https://nanda.medi                        Zhang, Ollie Liu, Jiaqi Chen, Huan Zhang, Zhaoyang
     a.mit.edu/. Project site describing a decentralized                  Yu, Haochen Shi, Boyan Li, Dekun Wu, Fengwei
     “agentic web,” with links to papers and events.                      Teng, Xiaojun Jia, Jiawei Xu, Jinyu Xiang, Yizhang
                                                                          Lin, Tianming Liu, Tongliang Liu, Yu Su, Huan
[38] Aditya Challapally, Chris Pease, Ramesh Raskar, and                  Sun, Glen Berseth, Jianyun Nie, Ian Foster, Logan
     Pradyumna Chari. The genai divide: State of ai in                    Ward, Qingyun Wu, Yu Gu, Mingchen Zhuge, Xi-
     business 2025. Technical report, MLQ.ai and Project                  angru Tang, Haohan Wang, Jiaxuan You, Chi Wang,
     NANDA, July 2025. URL https://mlq.ai/med                             Jian Pei, Qiang Yang, Xiaoliang Qi, and Chenglin
     ia/quarterly_decks/v0.1_State_of_A                                   Wu. Advances and challenges in foundation agents:
     I_in_Business_2025_Report.pdf. Prelimi-                              From brain-inspired intelligence to evolutionary, col-
     nary findings from AI implementation research.                       laborative, and safe systems, 2025. URL https:
                                                                          //arxiv.org/abs/2504.01990.
[39] Capgemini Research Institute. Rise of agentic ai, July
     2025. URL https://www.capgemini.co                              [46] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang,
     m/wp-content/uploads/2025/07/Final                                   Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang,
    - Web- Version-Report- AI-Agents.pdf.                                 Xu Chen, Yankai Lin, et al. A survey on large lan-
     Global executive survey on AI agents; key findings                   guage model based autonomous agents. Frontiers of
     summarized on the report landing page.                               Computer Science, 18(6):186345, 2024.

                                                                20
                                             Measuring Agents in Production

[47] Junyu Luo, Weizhi Zhang, Ye Yuan, Yusheng Zhao,                     Myaskovsky, Felix Weissenberger, Keran Rong, Ryu-
     Junwei Yang, Yiyang Gu, Bohan Wu, Binqi Chen,                       taro Tanno, Khaled Saab, Dan Popovici, Jacob Blum,
     Ziyue Qiao, Qingqing Long, Rongcheng Tu, Xiao                       Fan Zhang, Katherine Chou, Avinatan Hassidim, Bu-
     Luo, Wei Ju, Zhiping Xiao, Yifan Wang, Meng Xiao,                   rak Gokturk, Amin Vahdat, Pushmeet Kohli, Yossi Ma-
     Chenwu Liu, Jingyang Yuan, Shichang Zhang, Yiqiao                   tias, Andrew Carroll, Kavita Kulkarni, Nenad Toma-
     Jin, Fan Zhang, Xian Wu, Hanqing Zhao, Dacheng                      sev, Vikram Dhillon, Eeshit Dhaval Vaishnav, By-
     Tao, Philip S. Yu, and Ming Zhang. Large language                   ron Lee, Tiago R D Costa, José R Penadés, Gary
     model agent: A survey on methodology, applications                  Peltz, Yunhan Xu, Annalisa Pawlosky, Alan Karthike-
     and challenges, 2025. URL https://arxiv.or                          salingam, and Vivek Natarajan. Towards an ai co-
     g/abs/2503.21460.                                                   scientist. https://storage.googleapis.c
                                                                         om/coscientist_paper/ai_coscientist.
[48] Francesco Piccialli, Diletta Chiaro, Sundas Sarwar,                 pdf, Feb 2025.
     Donato Cerciello, Pian Qi, and Valeria Mele. Agentai:
     A comprehensive survey on autonomous agents in                 [55] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng
     distributed ai for industry 4.0. Expert Systems with                Li, Weiming Lu, and Yueting Zhuang. Hugginggpt:
     Applications, 291:128404, 2025. ISSN 0957-4174.                     Solving ai tasks with chatgpt and its friends in hugging
     doi: https://doi.org/10.1016/j.eswa.2025.128404. URL                face, 2023. URL https://arxiv.org/abs/23
     https://www.sciencedirect.com/scie                                  03.17580.
     nce/article/pii/S0957417425020238.
                                                                    [56] Sahana Chennabasappa, Cyrus Nikolaidis, Daniel
[49] Aske Plaat, Max van Duijn, Niki van Stein, Mike                     Song, David Molnar, Stephanie Ding, Shengye Wan,
     Preuss, Peter van der Putten, and Kees Joost Batenburg.             Spencer Whitman, Lauren Deason, Nicholas Doucette,
     Agentic large language models, a survey, 2025. URL                  Abraham Montilla, Alekhya Gampa, Beto de Paola,
     https://arxiv.org/abs/2503.23037.                                   Dominik Gabi, James Crnkovich, Jean-Christophe
                                                                         Testud, Kat He, Rashnil Chaturvedi, Wu Zhou, and
[50] Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel, Yilun
                                                                         Joshua Saxe. Llamafirewall: An open source guardrail
     Zhao, Roy Bar-Haim, Arman Cohan, and Michal
                                                                         system for building secure ai agents, 2025. URL
     Shmueli-Scheuer. Survey on evaluation of llm-based
                                                                         https://arxiv.org/abs/2505.03574.
     agents, 2025. URL https://arxiv.org/abs/
     2503.16416.                                                    [57] Akshara Prabhakar, Roshan Ram, Zixiang Chen, Sil-
                                                                         vio Savarese, Frank Wang, Caiming Xiong, Huan
[51] Mahmoud Mohammadi, Yipeng Li, Jane Lo, and
                                                                         Wang, and Weiran Yao. Enterprise deep research:
     Wendy Yip. Evaluation and benchmarking of llm
                                                                         Steerable multi-agent deep research for enterprise an-
     agents: A survey. In Proceedings of the 31st ACM
                                                                         alytics, 2025. URL https://arxiv.org/abs/
     SIGKDD Conference on Knowledge Discovery and
                                                                         2510.17797.
     Data Mining V.2, KDD ’25, page 6129–6139. ACM,
     August 2025. doi: 10.1145/3711896.3736570. URL
                                                                    [58] Saurabh Jha, Rohan Arora, Yuji Watanabe, Takumi
     http://dx.doi.org/10.1145/3711896.3
                                                                         Yanagawa, Yinfang Chen, Jackson Clark, Bhavya
     736570.
                                                                         Bhavya, Mudit Verma, Harshit Kumar, Hirokuni Ki-
[52] Feng He, Tianqing Zhu, Dayong Ye, Bo Liu, Wanlei                    tahara, Noah Zheutlin, Saki Takano, Divya Pathak,
     Zhou, and Philip Yu. The emerged security and privacy               Felix George, Xinbo Wu, Bekir O. Turkkan, Gerard
     of llm agent: A survey with case studies. ACM Comput.               Vanloo, Michael Nidd, Ting Dai, Oishik Chatterjee,
     Surv., October 2025. ISSN 0360-0300. doi: 10.114                    Pranjal Gupta, Suranjana Samanta, Pooja Aggarwal,
     5/3773080. URL https://doi.org/10.1145/                             Rong Lee, Pavankumar Murali, Jae wook Ahn, Deban-
     3773080. Just Accepted.                                             jana Kar, Ameet Rahane, Carlos Fonseca, Amit Parad-
                                                                         kar, Yu Deng, Pratibha Moogi, Prateeti Mohapatra,
[53] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi                        Naoki Abe, Chandrasekhar Narayanaswami, Tianyin
     Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest,                   Xu, Lav R. Varshney, Ruchi Mahindru, Anca Sailer,
     and Xiangliang Zhang. Large language model based                    Laura Shwartz, Daby Sow, Nicholas C. M. Fuller, and
     multi-agents: A survey of progress and challenges,                  Ruchir Puri. Itbench: Evaluating ai agents across
     2024. URL https://arxiv.org/abs/2402                                diverse real-world it automation tasks, 2025. URL
     .01680.                                                             https://arxiv.org/abs/2502.05352.

[54] Juraj Gottweis, Wei-Hung Weng, Alexander Daryin,               [59] Anthropic. Developing a computer use model. An-
     Tao Tu, Anil Palepu, Petar Sirkovic, Artiom                         thropic News, October 2024. URL https://www.

                                                               21
                                            Measuring Agents in Production

     anthropic.com/news/developing-compu                               Enabling llm-based data processing with accuracy
     ter-use.                                                          guarantees in lotus. Proc. VLDB Endow., 18(11):
                                                                       4171–4184, September 2025. ISSN 2150-8097. doi:
[60] Jacob Jackson, Phillip Kravtsov, and Shomil Jain. Im-             10.14778/3749646.3749685. URL https://doi.
     proving cursor tab with online rl, September 2025.                org/10.14778/3749646.3749685.
     URL https://cursor.com/blog/tab-rl.
     Cursor Blog, Research.                                       [72] Llama Team, AI @ Meta. The llama 3 herd of models,
                                                                       2024. URL https://arxiv.org/abs/2407
[61] Jacob Teo, Nikhil Jha, Connor Fogarty, Gary Chang,
                                                                       .21783.
     Theodor Marcu, Edison Zhang, Albert Tam, Sean
     Sullivan, Swyx, and Silas Alberti. Introducing swe-          [73] Qwen Team. Qwen3 technical report, 2025. URL
     1.5: Our fast agent model, October 2025. URL                      https://arxiv.org/abs/2505.09388.
     https://cognition.ai/blog/swe-1-5.
     Cognition AI Blog.                                           [74] OpenAI. gpt-oss-120b & gpt-oss-20b model card,
                                                                       2025. URL https://arxiv.org/abs/2508
[62] Anthropic Engineering Team. How we built our multi-
                                                                       .10925.
     agent research system, June 2025. URL https:
     //www.anthropic.com/engineering/mu                           [75] Anthropic. Claude: AI Assistant for Next-Generation
     lti-agent-research-system. Anthropic                              Tasks. www.anthropic.com, 2025.
     Engineering Blog.
                                                                  [76] OpenAI. OpenAI Platform Models. https://pl
[63] Block, Inc. goose: an open source ai agent built for              atform.openai.com/docs/models, 2025.
     developers, 2025. URL https://block.gith                          Accessed: December 5, 2025.
     ub.io/goose/. Project homepage.
                                                                  [77] Omar Khattab, Keshav Santhanam, Tarun Reuel, Sara
[64] OpenAI. Codex, 2025. URL https://openai.c
                                                                       Saad-Falak, Jack Hall, Matei Zaharia, and Christopher
     om/codex/. Product page.
                                                                       Potts. Dspy: Compiling declarative language model
[65] Gemini CLI Maintainers. Welcome to gemini cli docu-               pipelines into self-improving systems. In NeurIPS,
     mentation, 2025. URL https://geminicli.co                         2024.
     m/docs/. Project documentation.
                                                                  [78] Qizheng Zhang, Changran Hu, Shubhangi Upasani,
[66] Cline Bot Inc. Cline: The open coding agent, 2025.                Boyuan Ma, Fenglu Hong, Vamsidhar Kamanuru, Jay
     URL https://cline.bot/. Project homepage.                         Rainton, Chen Wu, Mengmeng Ji, Hanchen Li, Ur-
                                                                       mish Thakker, James Zou, and Kunle Olukotun. Agen-
[67] OpenHands. Openhands: The open platform for cloud                 tic context engineering: Evolving contexts for self-
     coding agents, 2025. URL https://openhands.                       improving language models, 2025. URL https:
     dev/. Project homepage.                                           //arxiv.org/abs/2510.04618.
[68] UC Berkeley RDI. Agentic AI Summit 2025. Event
                                                                  [79] Lakshya A Agrawal, Shangyin Tan, Dilara Soylu,
     page, August 2025. URL https://rdi.berk
                                                                       Noah Ziems, Rishi Khare, Krista Opsahl-Ong, Arnav
     eley.edu/events/agentic-ai-summit.
                                                                       Singhvi, Herumb Shandilya, Michael J Ryan, Meng
     Event date Aug 2, 2025; UC Berkeley; livestream
                                                                       Jiang, Christopher Potts, Koushik Sen, Alexandros G.
     available.
                                                                       Dimakis, Ion Stoica, Dan Klein, Matei Zaharia, and
[69] The AI Alliance. AI Agent SF Meetup #5 - Agents in                Omar Khattab. Gepa: Reflective prompt evolution
     Production. Event page, August 2025. URL https:                   can outperform reinforcement learning, 2025. URL
     //luma.com/x16vikh7. Event date Aug 5, 2025;                      https://arxiv.org/abs/2507.19457.
     Hosted by Bay Area AI; livestream available.
                                                                  [80] Langchain. https://www.langchain.com/.
[70] UC Berkeley Sky Computing Lab. Category: Retreats                 Accessed: 26 November 2025.
     and camps, 2025. URL https://sky.cs.ber
     keley.edu/category/retreats-and-cam                          [81] LangChain Inc. Langgraph, 2025. URL https:
     ps. News and event listings for UC Berkeley Sky                   //www.langchain.com/langgraph. Product
     Computing Lab retreats and camps.                                 page for the LangGraph agentic framework.

[71] Liana Patel, Siddharth Jha, Melissa Pan, Harshit             [82] crewAI. crewai: The leading multi-agent platform,
     Gupta, Parth Asawa, Carlos Guestrin, and Matei Za-                2025. URL https://www.crewai.com/. Prod-
     haria. Semantic operators and their optimization:                 uct homepage.

                                                             22
                                                Measuring Agents in Production

[83] LlamaIndex. Llamaindex: Redefine document work-                   [93] Hao Ma, Tianyi Hu, Zhiqiang Pu, Boyin Liu, Xiaolin
     flows with ai agents, 2025. URL https://www.ll                         Ai, Yanyan Liang, and Min Chen. Coevolving with the
     amaindex.ai/. Product homepage.                                        other you: Fine-tuning llm with sequential cooperative
                                                                            multi-agent reinforcement learning, 2025. URL http
[84] OpenAI. Swarm: Lightweight multi-agent orchestra-                      s://arxiv.org/abs/2410.06101.
     tion, 2025. URL https://github.com/opena
     i/swarm. GitHub repository.                                       [94] Alexander Novikov, Ngân Vũ, Marvin Eisenberger,
                                                                            Emilien Dupont, Po-Sen Huang, Adam Zsolt Wag-
[85] Cursor Team. Cursor ide: Ai-powered development                        ner, Sergey Shirobokov, Borislav Kozlovskii, Fran-
     with rule-based control. https://cursor.com                            cisco J. R. Ruiz, Abbas Mehrabian, M. Pawan Ku-
     /docs, 2025. Last Accessed October 4, 2025.                            mar, Abigail See, Swarat Chaudhuri, George Holland,
                                                                            Alex Davies, Sebastian Nowozin, Pushmeet Kohli,
[86] Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lak-
                                                                            and Matej Balog. AlphaEvolve: A coding agent for
     shya A. Agrawal, Bhavya Chopra, Rishabh Tiwari,
                                                                            scientific and algorithmic discovery. arXiv preprint
     Kurt Keutzer, Aditya Parameswaran, Dan Klein, Kan-
                                                                            arXiv:2506.13131, 2025.
     nan Ramchandran, Matei Zaharia, Joseph E. Gonzalez,
     and Ion Stoica. Why do multi-agent llm systems fail?,
     2025. URL https://arxiv.org/abs/2503
     .13657.

[87] Cursor Team. Composer: Building a fast frontier
     model with rl, October 2025. URL https://cu
     rsor.com/blog/composer. Cursor Blog, Re-
     search.

[88] Yuxiao Qu, Tianjun Zhang, Naman Garg, and Aviral
     Kumar. Recursive introspection: Teaching language
     model agents how to self-improve, 2024. URL http
     s://arxiv.org/abs/2407.18219.

[89] Shiyi Cao, Dacheng Li, Fangzhou Zhao, Shuo Yuan,
     Sumanth R. Hegde, Connor Chen, Charlie Ruan, Tyler
     Griggs, Shu Liu, Eric Tang, Richard Liaw, Philipp
     Moritz, Matei Zaharia, Joseph E. Gonzalez, and Ion
     Stoica. Skyrl-agent: Efficient rl training for multi-turn
     llm agent, 2025. URL https://arxiv.org/ab
     s/2511.16108.

[90] Siyu Yuan, Zehui Chen, Zhiheng Xi, Junjie Ye,
     Zhengyin Du, and Jiecao Chen. Agent-r: Training lan-
     guage model agents to reflect via iterative self-training,
     2025. URL https://arxiv.org/abs/2501
     .11425.

[91] Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei
     Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng,
     and Sujian Li. Agentbank: Towards generalized llm
     agents via fine-tuning on 50000+ interaction trajecto-
     ries, 2024. URL https://arxiv.org/abs/24
     10.07706.

[92] Chanwoo Park, Seungju Han, Xingzhi Guo, Asuman
     Ozdaglar, Kaiqing Zhang, and Joo-Kyung Kim. Ma-
     porl: Multi-agent post-co-training for collaborative
     large language models with reinforcement learning,
     2025. URL https://arxiv.org/abs/2502
     .18439.

                                                                  23
                                                       Measuring Agents in Production

Organization of Appendix
The appendix is organized as follows: in Appendix A we release the results on full survey dataset and report all statistics on
the complete set of agent systems (not only the deployed subset used in the main paper), including comparisons between
results on all agents and on deployed agents only; in Appendix B we provide additional analyses, such as our topic-
normalization procedure for agent domains, the outlier domains where agents operate, and more detailed breakdowns of the
challenges practitioners face when building agents. In Appendix C we unify our terminology for agents by defining what we
mean by tasks, subtasks, and steps, and we provide an overview of the agent workflow schema used throughout the paper. In
Appendix D we describe our interview protocol and present extended details of our case studies, including interview outlines
and anonymized interviewee demographics. Finally, in Appendix E we provide the full survey questionnaire, including
question wording and the branching logic that determines the survey flow.

A. Results on All Survey Data
In the main body of the paper, we focused on results filtered exclusively to deployed agents in production or pilot phases,
to highlight successful real-world practices under realistic operational constraints. In this appendix, we present the
corresponding results computed over [All Data]: all 306 valid survey responses, regardless of deployment stage. This
expanded view includes prototype, research, and legacy systems (sunset and retired), providing a broader perspective across
the full agent development lifecycle.
For ease of comparison, each [All Data] figure mirrors a figure in the main text and uses the same layout and question
wording. In the discussion below, we briefly summarize the key patterns in the full dataset and highlight how they compare
to the deployed-only subset.

                                                         68.3% (69)                      Finance & Banking                              33.3% (35)
            Increasing Productivity
                                                                                               Technology                      21.9% (23)
     Reducing Human Task-Hours                          63.4% (64)
                                                                                        Corporate Services                     21.0% (22)
        Automating Routine Labor                  43.6% (44)                                 Data Analytics             13.3% (14)
     Increasing Client Satisfaction            36.6% (37)                              Healthcare Services             11.4% (12)
       Reducing Human Expertise               32.7% (33)                           Research & Development              11.4% (12)
                 Novel Technology             32.7% (33)                                 Customer Support             10.5% (11)
                                          20.8% (21)                                 Software Development            9.5% (10)
Reducing Interdisciplinary Expertise
                                                                                       Legal & Compliance         6.7% (7)
     Faster Failure Response Time        18.8% (19)
                                                                                                     Retail    2.9% (3)
                     Risk Mitigation    16.8% (17)                                                   Other                 17.1% (18)
                                   0% 20% 40% 60% 80% 100%                                                0%    10% 20% 30% 40% 50% 60%
                                          % of Responses                                                                 % of responses

          (a) Reasons Practitioners Build AI Agents                                                  (b) Application Domains

Figure 14. [All Data] Overview of Agentic AI system motivations and domains across all development stages (Production, Pilot, Prototype,
and Research). These figures correspond to Figure 1 (a) and Figure 2 (b) in the main text but include all survey data. (a) Reasons
practitioners build AI agents (N = 101). Increasing productivity remains the most selected benefit across the full dataset. (b) Application
domains where practitioners build agents (N = 105). Note that this is a multi-class classification question where each system may be
assigned to multiple domain categories, and thus the proportions do not sum to 1.


A.1. Applications, Users, and Requirements
Motivations and application domains. Figure 14a reproduces our analysis of motivations for using agents over non-
agentic alternatives using all survey responses. We observe that the overall ranking of benefits is highly stable compared to
deployed only agents as shown in Figure 1: increasing productivity and efficiency remains the most frequently selected
reason for adopting agents, followed by reducing human task-hours and automating routine labor .
For application domains of agents, (Figure 14b) become even more diverse in the full dataset compared to deployed only
agents (Figure 2). The same high-level industries i.e., finance and banking, technology, and corporate services remain
prominent. However, the long tail of “other” domains grows, reflecting additional experimental and research systems in

                                                                      24
                                                                         Measuring Agents in Production
                                                                                                                     60%
                     Internal                                                     54.4% (56)                         50%
                  Employees                                                                                                               34.2% (27)




                                                                                                    Percentage (%)
                    External                                35.9% (37)                                               40%
                  Customers                                                                                                       25.3% (20)
                                                                                                                     30%                                                          19.0% (15)
                 Non-Agentic      4.9% (5)
                   Software                                                                                          20% 11.4% (9)
                                                                                                                                                                7.6% (6)
    Other AI Agents              3.9% (4)                         Human user
                                                                  Non-human user                                     10%                                                   2.5% (2)
                            0%          20%           40%           60%        80%                                    0%




                                                                                                                           nd


                                                                                                                                     s

                                                                                                                                              tes

                                                                                                                                                                urs


                                                                                                                                                                           y

                                                                                                                                                                                      et
                                                                                                                                                                       da
                                                                                                                                  nd




                                                                                                                                                                                 it s
                                                                                                                           co




                                                                                                                                         nu

                                                                                                                                                            Ho
                                                 % of Responses




                                                                                                                                  co




                                                                                                                                                                      >1

                                                                                                                                                                               lim
                                                                                                                       se




                                                                                                                                         Mi
                                                                                                                                Se
                                                                                                                     ub




                                                                                                                                                                            No
                                                                                                              <S
                                                                                                                                              Latency Tolerance
                                        (a)
                                                                                                           (b)
 Figure 15. [All Data] Overview of Agentic AI system characteristics across all development stages in terms of primary end users and
 latency requirements. This figure corresponds to Figure 5b in the main text but includes all survey data. (a) Distribution of primary end
 users (N =103), where hatched bars (///) denote human end-users; and (b) Reported tolerable end-to-end response latency for all systems
 (N =84). The high percentage of human end-users and tolerance for minute-level latency are consistent across the full dataset.


                 50%                                                                   14                                                                 50%
                                                                                30%
                 40%        12                                                  25%            11                                                         40%    33




                                                                                                                                         % of Responses
                                                               % of Responses
% of Responses




                                                                                                       10
                 30%                        10                                  20%                                                                       30%
                                                                                15%                                    7                                              20 20
                                  7                                                                                         6
                 20%                              6                                                                                                       20%
                                                                                10%                                                                                                        9
                 10%                                                             5%                                                                       10%                     4 3
                  0%                                                             0%                                                                       0%


                                                                                                                                                                   1-4
                                                                                                                                                                     0
                                                                                                                                                             Hu Tens
                                                                                                                                                              ou ds
                                                                                                                                                               No nds
                                                                                                                                                                     it
                                                                                 25 50
                                                                                 50 00
                                                                                 2.5 .5k
                                                                                        0k
                                                                                        k+




                                                                                                                                                                 5-1




                                                                                                                                                                 lim
                         1
                                 2
                                      3
                                              4+




                                                                                                                                                            Th ndre
                                                                                    k-1
                                                                                     10
                                                                                    0-2
                                                                                    0-5




                        Number of Distinct Models
                                                                                   0-2




                                                                                                                                                                sa
                                                                                      Instruction Length (tokens)                                               Autonomous Steps/Cycles
                                      (a)                                                                (b)                                                                   (c)

 Figure 16. [All Data] Overview of core components configurations and architectures across all agents. This figure corresponds to Figure 8
 in the main text but includes all survey data. (a) Number of distinct models combined to solve a single logical task (N =35). Deployed
 agents (Figure 8a) tend to use fewer models compared to all data, as the full dataset includes more experimental systems that utilize a
 higher number of distinct models; (b) Distribution of prompt lengths in terms of tokens (N =48). Prompt length remains pretty similar in
 both the deployed-only (Figure 8b) and all-data subsets; and (c) Number of autonomous execution steps before user intervention (N =89).
 Results on all survey data allows for a greater number of steps before human interference compared to deployed agents only (Figure 8c),
 reflecting the stricter need for control and monitoring in production environments.



  areas such as education, creative tools, and scientific workflows that have not yet reached deployment.


  End users and latency requirements. Consistent with the deployed-only subset, the vast majority of systems in the full
  dataset still target human users as shown in Figure 15a, with internal employees and external customers together comprising
  most end-user bases. The relative proportions shift only slightly when we include prototypes, suggesting that human-centric
  interaction remains the default even in early experimentation.
  Latency requirements also similarly remain relaxed in the full dataset (Figure 15b compared to Figure 5b). Most teams still
  report tolerating response times on the order of minutes, with a non-trivial fraction indicating that no explicit latency limit
  has been set. Compared to deployed agents only, the fraction of agents with undefined latency budgets is slightly higher in
  [All Data], which is consistent with prototypes and research artifacts that have not yet been hardened with production SLOs.
  Overall, these figures confirm that the preference for latency-relaxed, quality-focused applications is not an artifact of our
  deployment filter.

                                                                                               25
                                                   Measuring Agents in Production

A.2. Models, Architectures, and Prompting
Core components and autonomy. Figure 16 summarizes core component configurations and agent architectures over the
full dataset and corresponds to Figure 8 in the main text. Compared to deployed agents (Figure 8a), distribution of number
of distinct models used exhibits a heavier tail: non-deployed and research systems are more likely to combine many distinct
models, leading to a higher incidence of configurations with four or more models. This pattern aligns with our qualitative
observation that teams explore richer multi-model setups during early experimentation, then consolidate to a smaller, more
manageable set of models as they move toward deployment.
Prompt lengths remain broadly similar between the deployed-only (Figure 8b) and full datasets ((Figure 16b) .
Comparison between Figure 8c and Figure 16c reveals a clearer separation in autonomy. When we include all agents,
systems allow a greater number of autonomous steps or cycles before human intervention compared to deployed agents only.
Experimental and research systems are more likely to sit in the “tens of steps” and “no explicit limit” regimes, whereas
production deployments concentrate in the low-step regime to control cost, latency, and failure amplification. Taken together,
these results reinforce our interpretation that bounded autonomy is a deliberate design choice for production reliability,
while higher autonomy is more common in exploratory settings.


Prompt construction strategies and frameworks. Figure 17a reproduces our analysis of prompt construction and
framework usage using all survey responses. The results show that human-crafted prompts remain central across the full
dataset: fully manual and manual+LLM strategies are still the dominant modes. However, when we include non-deployed
agents, we see a modest shift toward more automated prompting: fully manual prompting is slightly more common among
deployed agents (Figure 7), while the [All Data] distribution shows somewhat higher use of “fully autonomous” prompting
and prompt optimizers. This suggests that automated prompt construction is currently used more as an experimental
technique and is less frequently adopted in production systems where controllability is critical.
Figure 17b compares framework usage across all agents and corresponds to Figure 17b in the main text. The overall split
between using any framework vs. no framework remains nearly identical between the full dataset and deployed-only subset,
indicating that teams decide early whether to invest in a framework-based stack or implement their own orchestration. Within
the “framework” group, the Other category expands slightly in [All Data], reflecting experimentation with a broader
variety of less common or homegrown frameworks during research and prototyping stages, beyond the dominant framework
families.

                                                                                                                BeeAI
       Manual + AI                               50.6% (43)                                          70%        LlamaIndex
                                                                                                                Other                     60.5%
                                      28.2% (24)                                                     60%
      Fully Manual                                                                                              CrewAI
                                                                                                                                           4.7%
                                                                                    % of Responses




                                                                                                     50%        LangChain/LangGraph
 Prompt Optimizer          8.2% (7)                                                                           39.5%                        14.0%
                                                                                                     40%
 Fully Autonomous         5.9% (5)                                                                   30%                                   14.0%

                                                                                                     20%
Predefined Library      3.5% (3)                                                                     10%                                   23.3%

                  0%        20%     40%     60%          80%                                          0%         No                         Yes
                               % of Responses                                                               Did Not Use               Used Framework
                                                                                                           Any Framework

                                        (a)                                                                                   (b)

Figure 17. [All Data] Overview of core technical implementations: Prompt Construction and Framework Usage. The left and right figures
correspond to Figure 7 and Figure 9 in the main text respectively but they include all survey data. (a) Distribution of prompt construction
strategies across all agents (N =85). Human input remains central to prompt crafting, however, fully manual is slightly more common
in deployed agents (Figure 7) compared to all data in the left plot. Similarly ‘fully autonomous’ prompting is more common in the All
Data, suggesting that manual prompting is more favored for production systems. (b) Frameworks reported to support critical functionality
(N =43). The percentage of practitioners using a framework versus not using one remains almost exactly the same between the full dataset
(right plot) and the deployed-agents-only (Figure 9). The "other frameworks" category increases slightly in the full dataset compared to
deployed agents only, likely reflecting more diverse experimentation in non-production systems.



                                                                    26
                                                                                Measuring Agents in Production

  A.3. Evaluation Practices for All Agents
  Figure 18 presents evaluation practices across all agents and mirrors Figure 10 in the main text. Figure 18a shows distribution
  of comparison against non-agentic baselines. When we include prototypes and research systems, the fraction of teams that
  explicitly compare their agents to alternative solutions is slightly lower than in the deployed-only subset (34% in all data vs.
  38.7% in deployed agents in Figure 10a). This suggests that some experimental agents are perhaps still in early stages where
  rigorous baseline comparison has not yet been prioritized, or where teams are primarily exploring feasibility rather than
  relative gains.
  Figure 18b reports the distribution of different evaluation methods. The ordering of methods remains unchanged: human-in-
  the-loop (manual) evaluation is still the most common strategy, followed by model-based evaluation (LLM-as-a-judge).
  However, manual evaluation is somewhat more prevalent among deployed agents (Figure 10b), whereas the [All Data]
  distribution shows a relatively higher share of automated methods. This is consistent with the idea that experimental and
  research systems may rely more on automated or lightweight checks, while production systems invest more heavily in
  human verification before and during deployment.
  Figure 18c visualizes co-occurrence patterns between evaluation strategies. Human-in-the-loop evaluation remains the
  central hub in the evaluation graph, with high overlap with all other methods in the full dataset. At the same time, its
  co-occurrence with other strategies is slightly lower in [All Data] than in the deployed-only subset (Figure 10c), reflecting
  that some experimental systems use model-based or rule-based checks without consistently pairing them with human review.
  In contrast, deployed agents are more likely to combine automated evaluation with human verification perobably for higher
  assurance.

                 100%                                                                                                                                                         60
                               Alternative does not exist                            Manual
                                                                       (Human in the Loop)
                                                                                                                  63.3% (31)           Manual 63.3%
                                                                                                                                               (31)
                                                                                                                                                    32.7% 28.6% 26.5%
                                                                                                                                                     (16)  (14)  (13)
                 80%           Alternative might exist
                                                  66.0%                         Model Based                 46.9% (23)                                                        50
                                                                                                                                   Model Based 32.7% 46.9% 24.5% 18.4%




                                                                                                                                                                               % of Responses
% of Responses




                                                                     (e.g., LLM-as-a-Judge)                                                     (16)  (23)  (12)  (9)
                 60%
                                                                          Cross-Referencing                40.8% (20)                                                         40
                                                 42.6%      (e.g., RAG, Knowledge Graphs)
                                                                                                                               Cross-Referencing 28.6% 24.5% 40.8% 20.4%
                 40%       34.0%                                                                                                                  (14)  (12)  (20)  (10)
                                                                                  Rule Based                42.9% (21)                                                        30
                                                                       (e.g., Syntax Checks)
                 20%
                                                 23.4%                                                                              Rule Based 26.5%
                                                                                                                                                (13)
                                                                                                                                                     18.4% 20.4% 42.9%
                                                                                                                                                      (9)   (10)  (21)
                                                                        None of the above       8.2% (4)                                                                      20
                  0%         Yes                   No                                      0%   20% 40% 60% 80% 100%
                                                                                                                                             al

                                                                                                                                                      d




                                                                                                                                                                         d
                                                                                                                                                                g
                        Compared to              Did Not

                                                                                                                                                      e




                                                                                                                                                                          e
                                                                                                                                                            cin
                                                                                                                                            nu

                                                                                                                                                   as




                                                                                                                                                                       as
                         Alternative            Compare
                                                                                                                                          Ma




                                                                                                                                                            en
                                                                                                     % of Responses
                                                                                                                                                  lB




                                                                                                                                                                      le B
                                                                                                                                                          fer
                                                                                                                                                 de




                                                                                                                                                                 Ru
                                                                                                                                                       Re
                                                                                                                                              Mo

                                                                                                                                                      ss-
                                                                                                                                                   Cro
                                       (a)                                                                 (b)                                                  (c)

Figure 18. [All Data] Evaluation Practices in Agents. This figure corresponds to Figure 10 in the main text but includes all survey data
(N = 47). (a) Comparison to Alternatives: Shows whether participants explicitly compared their agent against a non-agentic baseline.
Deployed agents (Figure 10a show a higher comparison rate (38.7% in deployed vs. 34% in all data) of comparison to alternative solutions,
suggesting that experimental prototypes may not have invest as much on evaluation stages yet. (b) Evaluation Methods Distribution:
Distribution of different evaluation strategies reported by survey participants. Manual evaluation (human-in-the-loop) is used more
for deployed agents (Figure 10b) compared to the full dataset, which includes more experimental and research systems. Autonomous
evaluation methods are relatively less common in deployed agents compared to the data for all agents in oru survey. (c) Evaluation
Strategies Co-occurrence: Visualizes the pairwise overlap between evaluation strategies. Manual human-in-the-loop evaluation is still the
central strategy, but its co-occurrence with other methods is slightly lower in the all-data subset compared to deployed agents (Figure 10c),
indicating that autonomous evaluation methods have more complementary roles in in deployed agents.


  A.4. Data Handling, Latency Challenges, and Modalities Across All Agents
  Figure 19 corresponds to Figure 12 and Figure 11 in the main text but reports statistics across all survey responses.
  Figure 19 shows distribution of data sources for agents which is remarkably stable when moving from deployed agents
  only ( Figure 12) to [All Data] in Figure 19. This possibly indicates that the underlying data plumbing for agents is largely
  shared across lifecycle stages: teams tend to set up similar ingestion and handling pipelines during prototyping that then
  carry through to production with incremental hardening.
  In addition, Figure 19b reports how often latency is described as a problem across all systems. The distribution changes only
  modestly when compared to the deployed-only subset (Figure 11), and we again see that latency is not the dominant blocker

                                                                                                     27
                                                                   Measuring Agents in Production


          Database                                  76.7% (33)                                                    Latency Blocker                14.6% (6)
 Confidential data                             62.8% (27)
                                                                                             Deployable with Latency Gap                                         61.0% (25)
     Live user data                            62.8% (27)
Live non-user data                         48.8% (21)                                                      No Latency Concern                       24.4% (10)
Public online data                     37.2% (16)                                                                                         0% 20% 40% 60% 80% 100%
                                                                                                                                                 % of Responses
                  0%   20% 40% 60% 80% 100%
                             % of Responses
                                                  (a)                                                                                                   (b)

Figure 19. [All Data] The figures correspond to Figure 12 (a) and Figure 11 (b) in the main text but include all survey data. (a) Types
and modes of data ingestion and handling in all agent (N = 43). The distribution of data sources and handling methods did not change
substantially when moving from deployed agents only to all survey data. (b) Degree to which latency causes problems for all agent
systems (N = 46). The distribution of problematic latency did not change substantially when moving from deployed agents only to all
survey data, suggesting latency is not a primary deployment blocker across the development lifecycle.




for most agent deployments. This supports our broader conclusion that agents are currently concentrated in latency-relaxed
settings where quality and correctness dominate over strict real-time responsiveness.
Finally, Figure 20 mirrors Figure 13 in the main text but includes all survey data. The overarching trend remains the
same: growth is heavily concentrated in non-textual modalities, pointing towards increasingly multimodal agentic systems.
Interestingly, the emphasis on future support for non-text modalities is even stronger than in the deployed-only subset,
indicating that experimental and research agents are pushing more aggressively into multimodal directions (e.g., image,
audio, and structured data) that may not yet have reached stable production deployment.




                                                                    Modalities Currently Supports
                                                                                                                           93.2%




                                                  100%              Modalities to Support in Future
                                                                                                                                      81.8%
                                 % of Responses




                                                  80%
                                                                                                                63.6%
                                                                                            58.8%




                                                                                                                                         52.9%




                                                  60%
                                                                                 47.1%



                                                                                                        38.6%


                                                                                                                   35.3%
                                                                     32.4%




                                                                                                                              32.4%
                                                                             31.8%




                                                  40%
                                                                                                    23.5%
                                                           20.6%
                                                         13.6%




                                                                                         13.6%




                                                  20%
                                                                   6.8%




                                                   0%
                                                                                 l te es
                                                                                             s




                                                                      tur abul e
                                                        ata




                                                                       Ma angu ata
                                                                                     ag ral




                                                                              t e ne t
                                                                                    , lo ed
                                                                          tex e ge Tex
                                                              eo




                                                                                           d
                                                                              tia ag



                                                                                        Co




                                                                                 .g. rat
                                                                                        es




                                                                                        gs
                                                                                 Im mpo
                                                   cd




                                                                            L ar d
                                                           Vid

                                                                                     Im




                                                                             in e
                                                                          ch ag
                                                  tifi
                                       ien




                                                                              T
                                 Sc




                                                                    pa
                                                                   os




                                                                         al
                                                               Ge




                                                                   Na




                                                                                           Modalities

Figure 20. [All Data] Data modalities already supported (red) versus modalities planned for future support (blue) across all agents.
This figure corresponds to Figure 13 in the main text but includes all survey data. The trend of growth being heavily concentrated in
non-textual modalities remains consistent, pointing toward increasingly multimodal agent systems. However, comparing this figure with
the deployed-only subset shows that the full survey data in Figure 13 places an even stronger focus on non-textual modalities for future
support. (N =44)




                                                                                          28
                                              Measuring Agents in Production


                  Table 2. Survey Responses Recorded as ’Other’ For Domain Analysis and Topic Normalization.
 chemical                       proprietary-based networks      Telco                          GTM Operations
 supply chain                   food & beverage industry        construction                   automotive
 travel                         Advertising                     Beauty & wellness              Privacy
 entertainment & gaming         film & TV                       social media                   Paint industry



B. Analysis Details
B.1. Topic Normalization for RQ1
We then normalized these responses using an LLM-based semantic aggregation to merge semantically similar responses and
categorize the answers for conceptual consistency and to avoid repeated or redundant categories. The resulting categories
were manually reviewed to confirm semantic alignment. We then perform an LLM-based semantic mapping over each
survey response to assign one or more domain labels. For example, the Healthcare Services category includes answers
such as health care, medical, medicine, biomedicine, patient monitoring, virtual nursing, and care navigation. We use
LOTUS [71] to perform the semantic aggregation and semantic mapping and provide the relevant program snippets below.
We use gpt-4o-2024-08-06 as the LLM for both.

  Domain Classification with LOTUS Semantic Map

  df.sem_map(
      "Given the survey answer {N4 CQ}, and the provided classification labels, "
      + "answer with the list of labels that best categorize the survey answer.\n"
      + "You may ONLY choose labels from the list provided.\n"
      + "Provide your answer as a list of strings, e.g. [’label1’, ’label2’].\n"
      + "Please respond with the answer only and include only valid labels from "
      + "the provided list.\n"
      "Only list ’Other’ if no other label reasonably applies.\n"
      + f"Below are the classification labels: {categories_str}"
  )



  Domain Normalization with LOTUS Semantic Aggregation

  df.sem_agg(
      f"Given user answers to a survey question in {{N4 CQ}}, create a comprehensive
          bullet point list of answer categories. The survey question was: {header_map["
          N4 CQ"]}."
  )



B.2. Outlier Domains
Table 2 presents the domains that were mentioned only once across all reported Agentic AI use cases. These outlier domains
highlight the long-tail diversity of applications where Agentic AI is being explored beyond the dominant sectors such as
finance, technology, and enterprise.

B.3. Challenge Details
We asked participants to rank the major categories of challenges they encounter during the development or operation of
Agentic AI systems. Table 3 provides detailed descriptions of each challenge category identified in the survey, outlining
the main technical and organizational issues practitioners reported when building Agentic AI systems. The five categories
and their detailed definitions are provided in Table 3. Figure 21b illustrates how frequently each challenge category was
assigned a given rank. For example, ‘Core Technical Performance’ was ranked as the most significant challenge (#1) by 16
respondents, by far more than any other category, indicating it remains the dominant source of difficulty in current Agentic
AI system development. ‘Core Technical Performance’ encompasses a wide range of issues, including robustness, reliability,

                                                             29
                                                      Measuring Agents in Production


                                                                                                                               Core Technical Focus 37.9%
                                                                                                                                                     (11)
                                                                                                                                                          20.7% 24.1% 0.0% 17.2%
                                                                                                                                                            (6)   (7)  (0)   (5)
            Core Technical Focus                      37.9% (11)




                                                                                   Development Priority Categories
                                                20.7% (6)                                                                   Data and Model Integrity 20.7% 24.1% 27.6% 13.8% 13.8%
         Data and Model Integrity                                                                                                                      (6)   (7)   (8)   (4)   (4)


System Integration and Validation           20.7% (6)                                                                System Integration and Validation 20.7%
                                                                                                                                                         (6)
                                                                                                                                                             31.0% 13.8% 31.0% 3.4%
                                                                                                                                                               (9)   (4)   (9)  (1)

      Compliance and User Trust             17.2% (5)                                                                  Transparency and Governance 3.4%   6.9%    6.9% 44.8% 37.9%
                                                                                                                                                    (1)     (2)     (2)    (13)    (11)
   Transparency and Governance       3.4% (1)
                                                                                                                          Compliance and User Trust 17.2%
                                                                                                                                                      (5)
                                                                                                                                                          17.2% 27.6% 10.3% 27.6%
                                                                                                                                                            (5)   (8)   (3)   (8)

                                0%    20% 40% 60% 80% 100%                                                                                        Rank 1 Rank 2 Rank 3 Rank 4 Rank 5
                                         % of Responses
                                                                                                                                                 Most Challenging <---> Least Challenging
                                                    (a)                                                                                                            (b)

Figure 21. Major challenge categories encountered across all Agentic AI systems (N = 29). (a) Distribution of top-ranked (Rank 1)
challenges for building agents in deployment. (b) Heatmap showing how frequently each category was assigned to different ranks of
difficulty (1 = most challenging, 5 = least challenging) across the deployed agents. Results show that Core Technical Performance remains
the primary friction point.



                                     Table 3. Major categories of challenges reported by participants.
     Challenge Category                          Representative Issues and Focus Areas
     Core Technical Performance                  Robustness and reliability—ensuring consistent, correct behavior in diverse and unpre-
                                                 dictable environments; scalability—supporting growth in users, data, and tasks without
                                                 performance degradation; real-time responsiveness—meeting latency and timing re-
                                                 quirements; resource constraints—managing compute, memory, and energy efficiently.
     Data and Model Integrity                    Data quality and availability—access to clean, timely, and relevant data; model and
                                                 concept drift—adapting to changes in data distributions and task definitions; versioning
                                                 and reproducibility—tracking models, data, and configurations for auditability.
     System Integration and Validation           Integration with legacy systems—connecting with existing infrastructure and APIs;
                                                 testing and validation—simulating and verifying agent behavior before deployment;
                                                 security and adversarial robustness—defending against manipulation and exploitation.
     Transparency and Governance                 Explainability and interpretability—making decisions understandable to humans; bias
                                                 and fairness—preventing discriminatory or unjust outcomes; accountability and respon-
                                                 sibility—clarifying who is liable for agentic decisions.
     Compliance and User Trust                   Privacy and data protection—ensuring adherence to data regulations (e.g., GDPR); user
                                                 trust and adoption—building confidence through transparency and reliability; regulatory
                                                 compliance—meeting legal standards for autonomy, safety, and transparency.




scalability, latency, and resource constraints. Its prevalence suggests that much of the community’s current effort is devoted
to ensuring that systems perform consistently and dependably under real-world conditions. Following closely were ‘Data and
Model Integrity’ and ‘System Integration and Validation’, both of which were reported as persistent sources of friction when
transitioning systems from research prototypes to production environments. In contrast, ‘Transparency and Governance’ and
Compliance and User Trust were ranked as lower-priority concerns. As shown in Figure 21b, ‘Transparency and Governance’
was most frequently placed in the fifth position (14 occurrences), indicating that while practitioners recognize its long-term
importance, it is not yet perceived as a primary bottleneck in current development cycles.

C. Terminology
To ensure clarity and consistency, we established a hierarchical taxonomy for agent execution. Figure 22 provides a
conceptual visualization of the key terminologies e.g., Task, Subtask, and Steps, as they are defined in our survey and applied
throughout the paper. This mapping illustrates the relationship between high-level user goals and the granular autonomous
actions taken by the agent.

                                                                      30
                                                          Measuring Agents in Production


                                                                                task
                User Input
                                          sub-task A                                    sub-task C               sub-task N
                                                                 sub-task B
                 Task
              Abstraction                  steps for A
                                                                                                                                     Output



                            Task abstraction is irrespective to agent execution. Execution can be determined by different agent architecture …

                                          agent loop                       workflow                  agent orchestration
                 Agent                                                 (graph, chain, etc..)

                 Control
               (examples of common
                   architectures)




Figure 22. Conceptual visualization of terminologies: “task", “subtask", “steps", used in Section 5 and how it maps to the survey definition.


D. In-Depth Case Study Data
For building in-depth case studies, we arranged interviews with technical experts willing and able to supplement the
published case study materials. Interviewers were selected to maintain organizational neutrality, assigned roles (lead,
assistants, observers), and completed a series of pre-, post-, and in-interview procedures.

D.1. Interview Outline
The structure of interviews was determined by a preset list of 11 topic groups (below), and the availability of respective
answers from open sources that need only be verified via interview. In general, interviewers were advised to prioritize topics
1–5 first, then 6–8, and finally 9–11 as time allowed.

1. The root problem (benefit) the system is addressing (providing): What is the ultimate benefit? What is the system
   replacing and why?

2. Key success metrics and evaluation mechanism: What tools, techniques, systems, etc. are used to ensure the system
   meets user and stakeholder objectives? Is data corresponding to the expected or past system behavior available for the
   evaluation?

3. Key aspects of the system design and implementation: What programming framework was used? What is the general
   architecture? What are the steps, stages, and cycles? How are common components (e.g. routers, LLM-as-a-Judge,
   other verifiers, HIL) combined and why? What is the ratio of automation to human interaction and why—by design or
   limitation?

4. The state of the system or its development: Is the system in production, or was it never meant for production (purely
   for AI research, learning, upskilling)? Was the system prototyped for production but abandoned—why, and what were
   the critical limitations? Were there surprises in the development or evaluation process? Did some things work better or
   worse than expected, and if so, what?

5. Known constraints or requirements of end-users and stakeholders: What are the security, confidentiality, regulatory,
   latency, SLO/SLA, or other requirements?

6. Advantage of an agentic AI system solution over alternative approaches: Do reasonable alternative solutions exist for
   this problem, or is this a novel solution made possible with Agentic AI? Against existing alternatives, has comparative
   analysis been conducted? What are the comparative benefits, costs, and return on investment (ROI)?

7. System dependencies and complexity: what is the quantity, quality, and availability of tools and data for verification
   and generation?

8. End-user quantity, expertise levels, and organizational domains. is it a product for internal-use only or public external
   use? Does it support multiple institutions? Are there institution-specific or regulatory boundaries limiting the quantity of

                                                                             31
                                                    Measuring Agents in Production

    users? Are target users domain experts or novices? How many of each user group are there and how many are targeted
    (order of magnitude)?...

 9. Estimated cost versus value or benefit: What is the estimated cost (sunk and expected ongoing costs) of developing
    and operating the system versus the estimated value or benefit? Is the respondent aware? What is the value, how is ROI
    being calculated?

10. System stakeholders: Who ultimately benefits from deployment? Who is impacted by safety, security, etc. failures and
    limitations? What is the expected impact on the company/institution (e.g. reduced hiring, retraining, broader user-base
    etc.)?

11. Your role and activities: What is your role in the development of the agentic AI system(s) you are describing?

 D.2. Interviewees Demographics
 To respect confidentiality agreements with case study sources, we present statistics on the sources in aggregate in Figure D.2.




 Figure 23. Case study sources are present in one to hundreds of countries. This shows the distribution of cases by sources’ country spread.




 Figure 24. Case study sources are present in 1 to 6 continents. This shows the distribution of cases by sources’ continental spread.



 E. Survey Questionnaire Details
 We crafted the questionnaire iteratively, refining it through early practitioner discussions. To facilitate broad participation,
 we limited the length, technical-depth, and disclosure-depth necessary to complete the questionnaire. All questions were
 optional and participation was entirely voluntary. Proceeding beyond certain questions required an answer or input however.
 For example, no participant could proceed without confirming they had read and understood Acknowledgement E.1-1.
 Figure 26 and Figure 27 shows the control-flows of the Core and Additional sections of the questionnaire respectively.
 Futher, all questions are intended for practitioners building AI Agents. Respondents who reported making technical
 contributions to more than 1 system (Table E.3 N1) were asked to focus all subsequent responses on 1 system of their choice
 (Acknowledgement E.1-2). Those who reported that they did not contribute to any systems they personally refer to as “AI
 agents” or “Agentic AI” systems were offered several options, such as commenting on terminology or their reason for
 starting the questionnaire, before being offered an early exit.

 E.1. Survey Acknowledgements
 Acknowledgment 1          All participants were required to acknowledge the following statement.

      You are invited to participate in a research study in which all data collected will be anonymized to protect your
      privacy. Your participation in this research is completely voluntary. The aim of the study is to understand key
      technical successes and challenges for deployment-track AI Agents and agentic systems, in order to steer further
      research and innovation in programming, runtime, and evaluation systems. We welcome as much or as little detail
      as you are willing to provide. Feedback on the survey/process itself is more than welcome. By proceeding with
      this survey, you acknowledge that you have read and understood the information provided above and consent to
      participate in this study. We sincerely appreciate your participation and value your contribution to this research.
      Thank you for your time and cooperation.

                                                                    32
                                                             Measuring Agents in Production

Acknowledgment 2 Further, all participants who stated they worked with more than 1 AI agent or agentic AI system were
required to acknowledge the following statement before proceeding further.

     To ensure consistency in your responses, please choose one agentic/assistant system to focus on throughout this
     survey. All your answers should relate to this same system. You may choose: * A system you are most familiar
     with, or * The system that is most developed among those you know — meaning closest to production with the
     most users. Please feel very, very welcome to submit additional survey responses for each system you are familiar
     with.

E.2. Survey Questions
We designed the questions to avoid response priming and facilitate downstream quantitative analysis, resulting in the
question-type distribution shown in Table 4.


E.3. Participant Contribution Distribution
As shown in Figure 25, this plot presents the distribution of how many Agentic AI systems participants reported contributing
to. Across the N =306 systems represented in the survey, most respondents contributed to only a single system, with fewer
individuals reporting involvement in multiple systems. This distribution highlights the breadth of participation across distinct
agent deployments rather than concentrated contributions from a small subset of practitioners.


                                                       30%        81     83
                                      % of Responses




                                                       20%                      53

                                                                                      25    31
                                                       10%
                                                             12                                      15
                                                                                                           6
                                                       0%
                                                             0
                                                                  1
                                                                       2
                                                                              3
                                                                                     4
                                                                                           5
                                                                                                 0
                                                                                                          +
                                                                                               6-1

                                                                                                      11




                                                                           # Agentic Systems
                                                                       Participants Contributed To

          Figure 25. Distribution of the number of Agentic AI systems that participants reported contributing to (N =306).


The exact survey questions and response choices are shown in the following sections.

                                                             Question Type            Frequency
                                                             MCSA                                    24
                                                             Free-Text                                8
                                                             MCMA                                     7
                                                             Rank-order                               5
                                                             Numerical Input                          3
                                                             Total Questions                         47

Table 4. Distribution of Question Types in Survey. Abbreviations: MCSA (Multiple-Choice Single-Answer), MCMA (Multiple-Choice
Multiple-Answer).




                                                                               33
                                          Measuring Agents in Production

Core Questions

 ID     Question                                  Response Choices
 N1     How many systems do you contribute        Numerical Input
        to that you would personally describe     —
        as "AI agent(s)", "agentic", or
        "assistant(s)"? Example Answer: 2.
        (Required)
 N1.1   Do your colleagues or stakeholders         MCSA
        call the systems you work on agentic,     Yes and yes
        and if so, would you be willing to        Yes and no, end questionnaire
        answer additional questions about the     No and no, end questionnaire
        one with which you are most familiar?
        Only shown if answer for N1 is = 0
 N2     May we contact you or your                Free-Text
        colleagues to learn more about your       —
        agentic/assistant systems? If so,
        please provide contact information. It
        will not be shared beyond the
        collaborators of this study or used for
        any other purpose. The question can
        be postponed after N14.
 N3     With respect to the system you chose,     Free-Text
        are references available (code            —
        repositories, blogs, publications,
        training data, evaluation data, or
        benchmark links)? If so, please
        provide links.
 N4     List as many keywords as you can          Free-Text
        think of describing the domains in        —
        which the target problem
        (opportunity) arises.
 N5     Which of the following best describes      MCSA
        the status of the agentic/assistant       In active production – Fully deployed and used by target end-users
        system on which you chose to focus        in a live operational environment
        your responses?                           Pilot or limited deployment – Deployed to a controlled group of
                                                  users or environments for evaluation, phased rollout, or
                                                  safety/security
                                                  Undergoing enterprise-grade development, not yet in pilot or
                                                  production – Actively being built, tested, or integrated, but not yet
                                                  piloted or deployed
                                                  Prototype for potential development – A functional early version
                                                  intended to (ideally) evolve into a production system
                                                  Retired or sunset – Previously in use or prototyping but now
                                                  decommissioned, cancelled, or replaced
                                                  Research or education artifact – Experimental or demonstrative,
                                                  never intended for production use
                                                  Unknown – The status is unclear or the question is not understood
                                                                                              Continued on next page




                                                         34
                                          Measuring Agents in Production

ID     Question                                   Response Choices
N5.1   Approximately how many target end           MCSA
       users are actively using this              0, 1-10, 10-49, 50-199, 200-499, 500-999, 1,000-9,999,
       production agentic system daily on         10,000-99,999, 100,000-999,999, 1,000,000 or more users, Not sure
       average? Only show if N5 answered.
N5.2   Approximately, how many tasks from         Free-Text
       target end-users is the system             —
       processing per day on average? Only
       show if N5 answered.
N6     Which of the following best describes       MCSA
       your primary role with respect to this     Oversight & Strategy — Executive or Senior Leadership (e.g.,
       agentic system?                            CTO, VP, Director), Product or Program Manager, Project Manager
                                                  or Scrum Master
                                                  Industry Development, Engineering, Research — Basic or
                                                  Advanced, Software Developer / Engineer, Machine Learning
                                                  Engineer, Data Scientist or Analyst, Researcher or Scientist
                                                  Academic Research & Engineering — Scientists, Students, Life
                                                  Long Learners
                                                  Operations & Infrastructure — MLOps / DevOps / Platform
                                                  Engineer, System Administrator or IT Support
                                                  Quality & User Experience — Quality Assurance / Test Engineer,
                                                  UX/UI Designer or Human Factors Specialist
                                                  Communication & Learning — Technical Writer or
                                                  Documentation Specialist, Educator or Trainer, Student or Intern
N7     What are the ultimate target gains of       MCMA
       enabling/deploying the system? Select      Workforce adaptation: reducing human expertise-levels or training
       the highest priority option(s). (Skip      generally required for the tasks
       the question if you do not know.)          Removing cross-domain, interdisciplinary knowledge
                                                  requirements, skills or training requirements
                                                  Increasing Productivity/Efficiency: increasing speed of task
                                                  completion over the previous human/automated system
                                                  Replacing time-consuming, low-skill, low-attention tasks with
                                                  automation
                                                  Mitigating Risk: reducing otherwise high or highly variable risk or
                                                  uncertainty
                                                  Decreasing human hours required regardless of skills, task
                                                  complexity, workforce expectations
                                                  Mitigating Failure/Loss: Decreasing time-to-intervention (security
                                                  breach, system failure, customer loss)
                                                  Increasing user engagement and/or increasing service quality
                                                  Enabling completion of tasks not possible with the previous
                                                  human/automated system
N7.1   Order the selected options according        Rank-order
       to their respective priority level. Only   Answers from N7
       shown if N7 Answered.
                                                                                             Continued on next page




                                                         35
                                          Measuring Agents in Production

ID     Question                                   Response Choices
N8     Who (what) are the primary direct           MCSA
       users or consumers of the                  Other AI Agent(s)
       agentic/assistant system? (Select one.)    Other NON-agentic software systems, tools, services
                                                  Humans operating INSIDE organizational boundaries (e.g.
                                                  employees operating inside a company and not their external
                                                  customers)
                                                  Human customers, general audience, operating OUTSIDE the
                                                  org authoring the agentic AI / assistant system
N9     Referring to the previously selected        MCMA
       description of direct users or             Operator (user initiates tasks, provides guidance, and determines a
       consumers as "user" (human or              task is finished)
       non-human), what does the system           Approver (without necessarily providing guidance to reach the
       require from users in terms of             solution, user approves a solutions generated by the agentic system)
       behavior(s), interaction(s), or role(s)?   Observer (user passively observes the agentic system is operating as
       To the agent/assistant, the target         expected)
       end-user is an. . .                        Optimizer (user actively intervenes to provide correction or improve
                                                  performance without necessarily being an Operator or Approver)
N9.1   Please sort the selected options with       Rank-order
       (1) as the primary intended role, (2) as   —
       a secondary role, and so on. Press and
       drag an option to sort. Only shown if
       N9 Answered.
N10    Using the previous definition of            MCSA
       "user", how many steps or cycles can       Four or fewer; Ten or fewer; Tens; Hundreds; Thousands; Millions;
       execute autonomously until user input      More; There is no limit, potentially infinitely many steps could
       is required?                               execute without user input or intervention
N11    What determines how many steps or           MCSA
       cycles can execute before a user’s         Problem complexity
       input is required?                         Non-determinism in the agentic planning or decision-making
                                                  Preset limits e.g. in the configuration, parameters, or defaults
                                                  I do not know, or I have not measured
N12    How are each agent’s system prompts         MCSA
       (instructions) constructed?                By hand, hard coded strings or templates e.g. LangChain templates
                                                  Using semi-automatic prompt engineering or optimization e.g. DSPy
                                                  Combination of manual and LLM or AI agents prompt creation and
                                                  refinement
                                                  Fully autonomously by agents
                                                  Using libraries or templates predefined by others e.g. open-source
                                                  I don’t know
N13    What is the average (typical)               Numerical Input
       estimated instruction length per agent     —
       in words or tokens? (Skip if you do
       not know.)
                                                                                              Continued on next page




                                                         36
                                           Measuring Agents in Production

ID     Question                                  Response Choices
N14    What is the maximum allowable              MCSA
       end-to-end result latency for the         I don’t know
       agentic/assistant system?                 No limit set yet, still in exploratory phase, not a latency-critical
                                                 system
                                                 Microseconds
                                                 Subsecond
                                                 Seconds
                                                 Minutes
                                                 Hours
                                                 1–4 days
                                                 Weeks
                                                 Months
                                                 More
N2     May we contact you or your                 Free-Text
       colleagues to learn more about your       —
       agentic/assistant systems? If so,
       please provide contact information. It
       will not be shared beyond the
       collaborators of this study or used for
       any other purpose. Only shown if
       question was postponed.
SEP    This is the end of the core questions.   MCSA
       Would you like to answer further        Yes; No
       questions?
EOS1   End of survey – any last comments or Free-Text
       feedback can be shared here. Only       —
       shows if SEP is No.




                                                         37
                                          Measuring Agents in Production

Additional Questions

 ID     Question                 Response Choices                          Additional Context
 O1     Select any/all of the     MCMA                                     Hover/click on the "i" for examples, definitions and descriptions.
        following methods        Manual (Human-in-the-loop):               Definitions:
        currently integrated     Expert Review                             Expert Review: Involve human specialists to validate content in high-stakes
        into your system that    Manual Citation Verification              or sensitive domains
        give you confidence      Crowdsourced Evaluation                   Manual Citation Verification: User ensures cited sources are accurate and
        your agentic/assistant   Red Teaming                               actually support the generated claims
        system is consistently   Automated Not-Model-Based                 Crowdsourced Evaluation: Collect feedback from diverse human reviewers
        producing high           Cross-Referencing:                        to assess quality and usefulness

        quality outputs,         External Fact-Checking                    Red Teaming: Humans manually test robustness by probing with adversarial
        whatever "high           Knowledge Graph Validation                or misleading prompts or actions to expose weakness
        quality" means in        Automated Citation Verification           External Fact-Checking: Retrieve supporting evidence from trusted sources
        your context.            Automated Model- and                      and validate claims e.g. using retrieval-augmented generation (RAG)
                                 Estimation-Based Methods:                 Knowledge Graph Validation: Cross-check facts against structured data like

                                 Self-Consistency Checks                   Wikidata or domain-specific ontologies

                                 Internal Confidence Estimation            Automated Citation Verification: Ensure cited sources are accurate and
                                 Critique Models                           actually support the generated claims
                                 Red Teaming using models                  Self-Consistency Checks: Generate multiple answers and compare for
                                 Cross-Model Validation                    consistency, use majority voting to select the most common answer, and/or
                                 LLM-as-a-Judge                            apply chain-of-thought reasoning to ensure logical consistency

                                 Automated Rule-Based Methods:             Internal Confidence Estimation: Score answers using log probabilities

                                 Grammar and Syntax Checks                 and/or estimate uncertainty with dropout or ensemble methods
                                 Domain-Specific Rules                     Critique Models: Use separate models to evaluate factuality, coherence, and
                                 Other:                                    overall quality of the output
                                 None of the above/below                   Red Teaming using models: Test robustness by probing with adversarial or
                                 I am not confident the system             misleading prompts to expose weakness

                                 consistently produces high quality        Cross-Model Validation: Compare outputs from different AI models to

                                 output yet                                identify consensus or discrepancies; Use Zero-Shot Critics, unrelated
                                                                           models to critique outputs without prior task-specific training
                                                                           Grammar and Syntax Checks: verify grammatical correctness and linguistic
                                                                           clarity with or without NLP models
                                                                           Domain-Specific Rules: Apply expert-defined rules for accuracy, tailored to
                                                                           specific fields like business, medicine, law or finance

                                                                                                                Continued on next page




                                                       38
                                         Measuring Agents in Production

ID     Question                 Response Choices                          Additional Context
O2     Sort the following        Rank-order                               Hover/click on the "i" for examples and definitions.
       categories from most     Data and Model Integrity:                 Definitions:
       to least important for   Data Quality and Availability             Data Quality and Availability: Accessing clean, timely, and relevant data for

       ongoing development      Model Drift and Concept Drift             decision-making
       and production           Versioning and Reproducibility            Model Drift and Concept Drift: Adapting to changes in data distributions
       deployment. Press        Core Technical Performance:               and task definitions
       and drag an option to    Robustness and Reliability                Versioning and Reproducibility: Tracking models, data, and configurations
       sort.                    Scalability                               for auditability
                                Real-Time Responsiveness                  Robustness and Reliability: Ensuring consistent, correct behavior in diverse

                                Resource Constraints                      and unpredictable environments
                                System Integration and Validation:        Scalability: Supporting growth in users, data, and tasks without performance
                                Integration with Legacy Systems           degradation
                                Testing and Validation                    Real-Time Responsiveness: Meeting latency and timing requirements in
                                Security and Adversarial Robustness       dynamic contexts
                                Transparency and Governance:              Resource Constraints: Managing compute, memory, and energy efficiently

                                Explanability and Interpretability        Integration with Legacy Systems: Seamlessly connecting with existing
                                Bias and fairness                         infrastructure and APIs
                                Accountability and Responsibility         Testing and Validation: Simulating and verifying agent behavior before
                                Compliance and User Trust:                deployment
                                Privacy and Data Protection               Security and Adversarial Robustness: Defending against manipulation and

                                User Trust and Adoption                   exploitation

                                Regulatory Compliance                     Explanability and Interpretability: Making decisions understandable to
                                                                          humans
                                                                          Bias and fairness: Preventing discriminatory or unjust outcomes
                                                                          Accountability and Responsibility: Clarifying who is liable for agentic
                                                                          decisions
                                                                          Privacy and Data Protection: Ensuring compliance with data regulations (e.g.

                                                                          GDPR)
                                                                          User Trust and Adoption: Building confidence through transparency and
                                                                          reliability
                                                                          Regulatory Compliance: Meeting legal standards for autonomy, safety, and
                                                                          transparency

O3     Have you compared         MCSA                                     —
       your agentic/assistant   Yes; No, alternatives might exist but I
       solution to a            have NOT formally compared them;
       non-agentic solution,    No, alternates DO NOT exist, my
       which of the             system provides truly novel
       following statements     functionality
       is most accurate?
O3.1   If it were entirely up    MCSA                                     —
       to you, would you        Yes
       choose the agentic       No
       solution over the
       alternatives? Only
       shown if answer for
       O3 is Yes
                                                                                                              Continued on next page




                                                        39
                                            Measuring Agents in Production

ID        Question                 Response Choices                          Additional Context
O3.1.1   You answered "Yes"         MCMA                                     —
         to "If it were entirely   Increased automation or reduced
         up to you, would you      manual effort
         choose the agentic        Enhanced user interface or usability
         solution over the         Scalability or support for more users
         alternatives?" Why,       ONLY Ease of software design,
         which of the              maintenance, model use or integration
         following functional      Improved performance or speed
         improvements does         For non-technical reasons ONLY, e.g.
         the new system offer      marketing/advertising, strategic
         compared to the           planning, ...
         previous solution?        Better integration with other systems
         (Select all that          Improved data accuracy or consistency
         apply.). Only shown       Enhanced security or compliance
         if answer to O3.1 is      Expanded features or capabilities
         Yes                       None of the above
O3.1.1.1 Order all selected         Rank-order                               —
         options according to      Answers from O3.1.1
         their respective
         priority level. -
         Improved
         performance or speed
         (Options from
         O3.1.1). Only shown
         if answer to O3.1.1
         has answers
O4       Thinking about the         MCSA                                     —
         state of the system       Either/Both; Assistant and NOT Agent
         you chose to focus        or agentic
         on, in your personal
         opinion, would you
         call it an "assistant"
         but not an AI Agent
         or agentic?
O4.1     Why do you refer to       Free-Text                                 —
         your system as AI         —
         agents or agentic?
         What makes it
         agentic in your
         opinion? Only shown
         if answer to O4 is
         Either/Both
                                                                                                  Continued on next page




                                                         40
                                         Measuring Agents in Production

ID     Question                Response Choices                           Additional Context
O4.2   Why do you refer to     Free-Text                                  —
       your systems or an     —
       "assistant rather than
       an "agent" or
       "agentic"? What
       makes it an assistant
       rather than an agentic
       system in your
       opinion? You may go
       back and change
       your previous answer
       if you use any of
       these terms to
       describe your system.
       Only shown if
       answer to O4 is
       Assistant and NOT
       Agent or agentic
O5     What is the minimum     MCSA                                       —
       level of expertise or  Highly skilled professionals —
       training (knowledge    Advanced education and specialized
       and skills) expected   knowledge (e.g., engineers, scientists,
       from typical           doctors); capable of complex tasks like
       end-users? (Select     coding, diagnostics, or system design
       the best option.)      Extensive domain experience — Deep
                              practical knowledge from years of
                              experience; having organizational or
                              domain knowledge, skilled in nuanced
                              tasks like troubleshooting or
                              decision-making
                              General education — High school
                              level education with basic digital skills
                              (e.g., using email, spreadsheets, or web
                              apps) and standard subject matter
                              knowledge
                              Minimal expertise required — Little
                              to no formal education; able to follow
                              simple instructions or perform basic
                              tasks (e.g., tapping buttons, entering
                              data)
                              Not sure
                                                                                               Continued on next page




                                                       41
                                       Measuring Agents in Production

ID   Question                 Response Choices                            Additional Context
O6   How would you rate        MCSA                                       —
     the return on            Exceptionally high ROI (ROI greater
     investment (ROI) of      than 150%)
     this agentic system      High ROI (ROI between 125%–150%)
     relative to its total    Acceptable ROI (ROI between
     cost of development,     90%–124%)
     operation,               Low ROI (ROI between 60%–89%)
     infrastructure and all   Poor ROI (ROI less than 60%)
     other costs? (Please
     select the option that
     best reflects your
     assessment.) Only
     shown if answer to
     N5 is "In active
     production – Fully
     deployed and used by
     target end-users in a
     live operational
     environment"
O7   How much do each          MCSA                                       —
     agent’s system           Tens of tokens
     prompt (instruction)     Hundreds of tokens
     lengths vary? (Skip if   Thousands of tokens
     you do not know.)        Ten of Thousands of tokens
                              More
O8   Compared to the           MCSA                                       —
     target latency for the   I don’t know
     system’s result          I don’t understand the question
     turn-around, how         Not problematic at all, the actual
     problematic is the       latency is better than expected and not a
     actual latency?          problem for deployment
     (Select one.)            Marginally problematic, but good
                              enough for deployment
                              Very problematic, the system can’t be
                              deployed without addressing the gap, or
                              the highest priority post-deployment
                              will be bringing down the latency
O9   What is the               MCSA                                       —
     maximum target           Microseconds; Subsecond; 1 to 10
     latency for              seconds; 10 to 60 seconds; A few
     determining a single     minutes; More; Less; I don’t know; I
     action, step, or         don’t understand the question
     response? (Select
     one.)
                                                                                               Continued on next page




                                                      42
                                        Measuring Agents in Production

ID      Question               Response Choices                          Additional Context
O10     What is the            Numerical Input                           —
        maximum number of      —
        distinct models used
        together to solve a
        single logical task?
        Skip if you do not
        know; estimates are
        fine.
O11     Are inference time      MCSA                                     Help: For the purposes of this question,
        scaling techniques     Yes; 0, No inference time scaling is      “inference time scaling” a.k.a. “test time
        used in your system?   used; I don’t know                        compute” refers to a family of techniques that
                                                                         call models multiple times or use a collection
                                                                         of models together, in place of a single model
                                                                         call and without modifying the weights or
                                                                         retraining any models, to answer a single
                                                                         question, choose a single next step, action,
                                                                         tool, etc...
O11.1   If inference time       MCSA                                     —
        scaling techniques     Tens
        are used,              Hundreds
        approximately how      Thousands
        many model calls are   Tens of thousands
        made per user query    Hundreds of thousands
        or task? Only shown    Millions
        if answer for O11 is   More
        Yes
O12     What data modalities    MCMA                                     —
        does the system        Natural Language Text
        process now (today)?   Tabular data
                               Software or machine generated text
                               including system logs, events, etc.
                               Code
                               Images
                               Videos
                               Image sequences or batches with
                               additional channels or metadata e.g.
                               geospatial, NMR scans
                               Scientific data not listed above
O13     What data modalities    MCMA                                     —
        will or should the     Same as O12
        system process in
        future (that it does
        NOT process now)?
                                                                                               Continued on next page




                                                       43
                                           Measuring Agents in Production

ID      Question                  Response Choices                          Additional Context
O13.1   You have selected the     Rank-order                                —
        following option(s)       Answers selected from O13
        for the question
        "What data
        modalities will or
        should the system
        process in future (that
        it does NOT process
        now)?": What are the
        barriers to processing
        them now? Sort the
        options from most to
        least important; press
        and drag an option to
        sort. Only shown if
        O13 is answered. If
        you don’t know, skip
        the question. - No
        barriers, just a matter
        of development time
O14     Which describes the        MCMA                                     —
        data handling             Ingests direct user input in real-time
        functions the             Ingests other real-time information as
        system(s) perform?        well as direct user input
        Select all that apply     Ingests information from other systems,
        and use the "Other"       e.g. databases, at most indirectly from
        box to detail.            end-users
                                  Retrieves persistent data from public
                                  external sources (e.g. the web)
                                  Retrieves non-public, confidential, or
                                  otherwise federated data
                                  Other
O15     Are you using an           MCSA                                     —
        openly                    Yes
        (commercially or          No, only an in-house not openly
        non-commerically)         available solution, or only standard
        available                 programming languages and tools e.g.
        agent-focused             Python, Java (not-agent-focused)
        programming               I don’t know
        framework (e.g.
        LangChain, CrewAI,
        Autogen,...) to
        implement your
        system?
                                                                                                 Continued on next page




                                                         44
                                        Measuring Agents in Production

ID     Question                Response Choices                          Additional Context
O16    From experimental       MCSA                                      —
       observations, which    OpenAI Swarm
       of the following       CrewAI
       supports most of       LangChain or LangGraph
       your assistant/agentic BeeAI
       system functionality   Autogen or AG2
       or design? Only        LlammaIndex
       shown if answer to     Other:
       O15 is Yes
O17    How long has it been    MCSA                                      —
       since active           Less than 3 months; 3–6 months; 6–12
       prototyping or initial months; 1–2 years; 2–5 years; More
       development started    than 5 years; I don’t know or prefer not
       on this                to say
       agentic/assistant
       system?
O18    How long have you       MCSA                                      —
       been working on this Same as O17
       agentic/assistant
       system?
EOS2   Thank you, this         Free-Text                                 —
       completes our          —
       questionnaire. Go
       back to change any
       of your answers, or
       click END to finalize
       them and exit. Any
       last comments or
       feedback can be
       shared here.




                                                      45
                               Measuring Agents in Production




Survey Start

                                       N1.1 is not
                                     "Yes and yes"
               N1 = 0
    N1                    N1.1                             End of Survey                  EOS1


                          N1.1 is "Yes
                           and yes"                                       SEP is No             SEP is Yes



          N1 > 0
                                                          N2                              SEP
                                                                              after N14



                           after N1/N1.1




                          N3



                          N4


            N5 answered

   N5.1                   N5
                                 N5 not an-
                                  swered

   N5.2                   N6


            N7 answered

   N7.1                   N7
                                 N7 not an-
                                  swered

                          N8


            N9 answered

   N9.1                   N9
                                 N9 not an-
                                  swered

                          N10



    N12                   N11
                                                           N2 postponed                         N2 already
                                                                                                answered



    N13                   N14

                           Figure 26. Survey flow: core questions




                                                     46
                                      Measuring Agents in Production




                                                                                 Section Start



                       O3.1                                                           O1


         O3.1 is Yes                                O3 is Yes
                                                                                      O2


                     O3.1.1                              O3.1 is No
                                                                                      O3

         O3.1.1 has
           at least                    O3.1.1 has
         one answer                                                                        O3 is not Yes
                                       no answers




                     O3.1.1.1                                                         O4

                                                                                                           O4 is "As-
                                                                 O4 is "Ei-                                sistant and
                                                                ther/Both"                                 NOT Agent
                                                                                                           or agentic"



                                                            O4.1                      O5                      O4.2



                                                             O7                       O6



             O13.1                                           O8                       O9

O13 answered
                                        O11 is not Yes
             O13                O12                         O11                      O10
   O13 not
  answered
                                                                    O11 is Yes

             O14                O15
                                                           O11.1

                                O16



                                O17



                                O18                        EOS2                        End of Survey

                                Figure 27. Survey flow: additional questions




                                                          47
